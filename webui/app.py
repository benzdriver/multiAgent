from fastapi import FastAPI, Request, HTTPException, WebSocket, WebSocketDisconnect, File, UploadFile, Form
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import os
import json
from pydantic import BaseModel
import sys
import asyncio
from typing import Dict, List, Any, Optional, Union
import shutil
from enum import Enum
from pathlib import Path
import re
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# æ›´æ–°å¯¼å…¥è·¯å¾„ï¼Œä½¿ç”¨serviceså±‚çš„æœåŠ¡
from services.clarifier_service import ClarifierService

from webui.api import clarifier_api, validator_api, fixer_api, generator_api

# ä½¿ç”¨æ–°çš„coreè·¯å¾„
from core.clarifier.clarifier import Clarifier
from core.clarifier.architecture_manager import ArchitectureManager
from core.clarifier.architecture_reasoner import ArchitectureReasoner

app = FastAPI(title="éœ€æ±‚æ¾„æ¸…ä¸æ¶æ„è®¾è®¡ç³»ç»Ÿ")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(clarifier_api.router, prefix="/api/clarifier", tags=["clarifier"])
app.include_router(validator_api.router, prefix="/api/validator", tags=["validator"])
app.include_router(fixer_api.router, prefix="/api/fixer", tags=["fixer"])
app.include_router(generator_api.router, prefix="/api/generator", tags=["generator"])

# åˆ›å»ºä¸€ä¸ªå…¨å±€çš„æœåŠ¡å®ä¾‹
clarifier_service = ClarifierService()

# é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="webui/static"), name="static")

# å…¨å±€çŠ¶æ€
clarifier: Optional[Clarifier] = None
conversation_history: List[Dict[str, str]] = []
global_state: Dict[str, Any] = {
    "requirements": {},
    "modules": {},
    "technology_stack": {},
    "requirement_module_index": {},
    "architecture_pattern": {},
    "validation_issues": {}  # æ–°å¢ï¼šä¿å­˜éªŒè¯é—®é¢˜
}
uploaded_files: List[str] = []
current_mode: str = None  # 'interactive' or 'file_based'
input_dir = "data/input"

# æ“ä½œæ¨¡å¼æšä¸¾
class OperationMode(str, Enum):
    FILE_BASED = "file_based"
    INTERACTIVE = "interactive"

# APIæ¨¡å‹
class Message(BaseModel):
    content: str

class ModeRequest(BaseModel):
    mode: str

class StartClarifierResponse(BaseModel):
    status: str
    message: Optional[str] = None

# é™æ€æ–‡ä»¶è·¯ç”±
@app.get("/", response_class=HTMLResponse)
async def read_root():
    with open("webui/static/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

# è·å–å…¨å±€çŠ¶æ€
@app.get("/api/state")
async def get_state():
    return global_state

# è·å–å¯¹è¯å†å²
@app.get("/api/history")
async def get_history():
    return conversation_history

# è·å–å½“å‰æ¨¡å¼
@app.get("/api/mode")
async def get_mode():
    return {"mode": current_mode}

# å¯åŠ¨æ¾„æ¸…å™¨
@app.post("/api/start_clarifier")
async def start_clarifier():
    global clarifier
    if clarifier is None:
        try:
            # ä½¿ç”¨core.clarifieråŒ…ä¸­çš„å·¥å‚æ–¹æ³•åˆ›å»ºClarifierå®ä¾‹
            from core.clarifier import create_clarifier, ensure_data_dir
            clarifier = create_clarifier(
                data_dir="data",
                use_mock=True,  # æµ‹è¯•é˜¶æ®µä½¿ç”¨æ¨¡æ‹ŸLLM
                verbose=True
            )
            print("âœ… Clarifierå·²æˆåŠŸåˆå§‹åŒ–")
            
            conversation_history.append({
                "role": "system",
                "content": "æ¬¢è¿ä½¿ç”¨éœ€æ±‚æ¾„æ¸…ä¸æ¶æ„è®¾è®¡ç³»ç»Ÿï¼è¯·é€‰æ‹©ä½¿ç”¨æ¨¡å¼ï¼š\n1. åŸºäºæ–‡ä»¶åˆ†æ (ä¸Šä¼ éœ€æ±‚æ–‡æ¡£)\n2. äº¤äº’å¼å¯¹è¯ (ç›´æ¥æè¿°æ‚¨çš„éœ€æ±‚)"
            })
            return {"status": "success", "message": "Clarifier initialized"}
        except Exception as e:
            print(f"âŒ Clarifieråˆå§‹åŒ–å¤±è´¥: {str(e)}")
            conversation_history.append({
                "role": "system",
                "content": f"åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            })
            return {"status": "error", "message": f"Clarifier initialization failed: {str(e)}"}
    return {"status": "success", "message": "Clarifier already initialized"}

# è·å–data/inputç›®å½•ä¸­çš„æ–‡ä»¶
def get_input_files(data_dir="data"):
    input_dir = Path(data_dir) / "input"
    if not input_dir.exists():
        return []
    
    return list(input_dir.glob('**/*.md'))

# ä¿®æ”¹set_modeå‡½æ•°ï¼Œç¡®ä¿èƒ½æ­£ç¡®æ£€æµ‹åˆ°æ–‡ä»¶
@app.post("/api/set_mode")
async def set_mode(mode_request: ModeRequest):
    global current_mode, conversation_history, uploaded_files
    
    mode = mode_request.mode
    if mode not in ["interactive", "file_based"]:
        raise HTTPException(status_code=400, detail="Invalid mode. Must be 'interactive' or 'file_based'.")
    
    current_mode = mode
    print(f"è®¾ç½®æ¨¡å¼ä¸º: {current_mode}")
    
    # å¦‚æœæ˜¯æ–‡ä»¶æ¨¡å¼ï¼Œè‡ªåŠ¨æ£€æŸ¥data/inputç›®å½•
    if mode == "file_based":
        # ç¡®ä¿uploaded_filesæ˜¯ç©ºçš„ï¼Œé˜²æ­¢é‡å¤
        uploaded_files = []
        
        # åˆ›å»ºinputç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs("data/input", exist_ok=True)
        print(f"æ£€æŸ¥ç›®å½•: data/input")
        
        # æ£€æŸ¥data/inputç›®å½•ä¸­çš„æ–‡ä»¶
        data_input_dir = Path("data/input")
        if data_input_dir.exists():
            print(f"data/inputç›®å½•å­˜åœ¨")
            md_files = list(data_input_dir.glob('**/*.md'))
            print(f"æ‰¾åˆ°äº† {len(md_files)} ä¸ª.mdæ–‡ä»¶")
            
            if md_files:
                # å°†è¿™äº›æ–‡ä»¶æ·»åŠ åˆ°å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
                for file_path in md_files:
                    abs_path = str(file_path.absolute())
                    uploaded_files.append(abs_path)
                    print(f"æ·»åŠ æ–‡ä»¶: {abs_path}")
                
                file_names = [f.name for f in md_files]
                msg = f"ç³»ç»Ÿæ£€æµ‹åˆ°inputç›®å½•ä¸­æœ‰ {len(md_files)} ä¸ªMarkdownæ–‡æ¡£: {', '.join(file_names)}"
                print(msg)
                conversation_history.append({
                    "role": "system",
                    "content": msg
                })
                
                conversation_history.append({
                    "role": "clarifier",
                    "content": "å·²æ£€æµ‹åˆ°inputç›®å½•ä¸­çš„æ–‡æ¡£ã€‚æ˜¯å¦ç«‹å³åˆ†æè¿™äº›æ–‡ä»¶ï¼Ÿè¯·è¾“å…¥Yå¼€å§‹åˆ†æã€‚"
                })
            else:
                print("æœªåœ¨data/inputç›®å½•ä¸­æ‰¾åˆ°.mdæ–‡ä»¶")
                conversation_history.append({
                    "role": "clarifier",
                    "content": "æœªåœ¨inputç›®å½•ä¸­æ‰¾åˆ°Markdownæ–‡ä»¶ã€‚è¯·ä¸Šä¼ æ–‡æ¡£åç»§ç»­ã€‚"
                })
        else:
            print("data/inputç›®å½•ä¸å­˜åœ¨")
            conversation_history.append({
                "role": "clarifier",
                "content": "inputç›®å½•ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºã€‚è¯·ä¸Šä¼ æ–‡æ¡£åç»§ç»­ã€‚"
            })
    
    return {"status": "success", "mode": current_mode}

# æ–‡ä»¶ä¸Šä¼ 
@app.post("/api/upload_file")
async def upload_file(file: UploadFile = File(...)):
    global uploaded_files, conversation_history
    
    if not file.filename.endswith('.md'):
        raise HTTPException(status_code=400, detail="Only markdown (.md) files are supported")
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(input_dir, exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        file_path = os.path.join(input_dir, file.filename)
        print(f"ä¿å­˜æ–‡ä»¶åˆ°: {file_path}")
        
        with open(file_path, "wb") as buffer:
            contents = await file.read()
            buffer.write(contents)
        
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ä¿å­˜åˆ°ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
        abs_path = str(Path(file_path).absolute())
        uploaded_files.append(abs_path)
        print(f"æ–‡ä»¶å·²æ·»åŠ åˆ°ä¸Šä¼ åˆ—è¡¨: {abs_path}")
        
        # æ›´æ–°å¯¹è¯å†å²
        conversation_history.append({
            "role": "system",
            "content": f"æ–‡ä»¶ '{file.filename}' ä¸Šä¼ æˆåŠŸã€‚"
        })
        
        if len(uploaded_files) == 1:
            conversation_history.append({
                "role": "clarifier",
                "content": "æ–‡ä»¶å·²ä¸Šä¼ ã€‚æ‚¨å¯ä»¥ç»§ç»­ä¸Šä¼ æ›´å¤šæ–‡ä»¶ï¼Œæˆ–è¾“å…¥Yå¼€å§‹åˆ†æå½“å‰æ–‡ä»¶ã€‚"
            })
        else:
            conversation_history.append({
                "role": "clarifier",
                "content": f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶ã€‚è¯·è¾“å…¥Yå¼€å§‹åˆ†æï¼Œæˆ–ç»§ç»­ä¸Šä¼ æ›´å¤šæ–‡ä»¶ã€‚"
            })
        
        return {"status": "success", "filename": file.filename}
    
    except Exception as e:
        print(f"æ–‡ä»¶ä¸Šä¼ å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# å¼€å§‹æ–‡æ¡£åˆ†æ
@app.post("/api/analyze_documents")
async def analyze_documents():
    """åˆ†æä¸Šä¼ çš„æ–‡æ¡£ï¼Œä½¿ç”¨LLMè¿›è¡Œç†è§£å¹¶æ›´æ–°å…¨å±€çŠ¶æ€"""
    global uploaded_files, conversation_history, global_state
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¼ çš„æ–‡ä»¶
    if not uploaded_files:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°å·²ä¸Šä¼ çš„æ–‡ä»¶")
    
    try:
        # è¯»å–æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹
        all_content = ""
        file_contents = []
        
        for file_path in uploaded_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    file_contents.append({"name": Path(file_path).name, "content": content})
                    all_content += f"\n\n--- {Path(file_path).name} ---\n{content}"
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        system_message = {
            "role": "system",
            "content": f"ç³»ç»Ÿå·²ç»æ¥æ”¶åˆ°ä»¥ä¸‹æ–‡æ¡£å†…å®¹è¿›è¡Œåˆ†æ:\n{all_content}"
        }
        conversation_history.append(system_message)
        
        # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        if not clarifier:
            raise HTTPException(status_code=500, detail="ç³»ç»Ÿå°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆå¯åŠ¨ç³»ç»Ÿ")
        
        # æ„å»ºæç¤º
        prompt = f"""
        åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœ:
        
        {all_content}
        
        è¯·è¿”å›å®Œæ•´çš„ç³»ç»Ÿæ¶æ„åˆ†æï¼ŒåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼ˆå¿…é¡»ä½¿ç”¨ä»¥ä¸‹ç¡®åˆ‡çš„JSONç»“æ„ï¼‰:
        
        {{
            "requirements": {{
                "req_1": {{ "id": "req_1", "name": "éœ€æ±‚åç§°", "description": "éœ€æ±‚æè¿°", "priority": "é«˜/ä¸­/ä½", "source": "æ¥æº" }},
                "req_2": {{ "id": "req_2", "name": "éœ€æ±‚åç§°", "description": "éœ€æ±‚æè¿°", "priority": "é«˜/ä¸­/ä½", "source": "æ¥æº" }}
                // å…¶ä»–éœ€æ±‚...
            }},
            "modules": {{
                "module_1": {{ 
                    "id": "module_1", 
                    "name": "æ¨¡å—åç§°", 
                    "description": "æ¨¡å—è¯¦ç»†æè¿°", 
                    "responsibilities": ["èŒè´£1", "èŒè´£2"], 
                    "dependencies": ["ä¾èµ–æ¨¡å—ID"], 
                    "technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
                    "module_name": "æ¨¡å—åç§°",  // ç¡®ä¿åŒ…å«è¿™ä¸ªå­—æ®µ
                    "target_path": "æ¨¡å—ç›®æ ‡è·¯å¾„"  // ç¡®ä¿åŒ…å«è¿™ä¸ªå­—æ®µ
                }},
                "module_2": {{ 
                    "id": "module_2", 
                    "name": "æ¨¡å—åç§°", 
                    "description": "æ¨¡å—è¯¦ç»†æè¿°",
                    "responsibilities": ["èŒè´£1", "èŒè´£2"],
                    "dependencies": ["ä¾èµ–æ¨¡å—ID"],
                    "technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
                    "module_name": "æ¨¡å—åç§°",  // ç¡®ä¿åŒ…å«è¿™ä¸ªå­—æ®µ
                    "target_path": "æ¨¡å—ç›®æ ‡è·¯å¾„"  // ç¡®ä¿åŒ…å«è¿™ä¸ªå­—æ®µ
                }}
                // å…¶ä»–æ¨¡å—...
            }},
            "technology_stack": {{
                "frontend": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
                "backend": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
                "database": ["æŠ€æœ¯1"],
                "devops": ["æŠ€æœ¯1"]
            }},
            "requirement_module_index": {{
                "req_1": ["module_1", "module_2"],
                "req_2": ["module_1", "module_3"]
                // éœ€æ±‚IDåˆ°æ¨¡å—IDçš„æ˜ å°„å…³ç³»
            }},
            "architecture_pattern": {{
                "name": "æ¶æ„æ¨¡å¼åç§°",
                "description": "æ¶æ„æ¨¡å¼æè¿°",
                "layers": ["å±‚1", "å±‚2", "å±‚3"],
                "patterns": ["è®¾è®¡æ¨¡å¼1", "è®¾è®¡æ¨¡å¼2"]
            }}
        }}
        
        è¯·ç¡®ä¿æ¯ä¸ªæ¨¡å—æœ‰æ¸…æ™°çš„åç§°ã€æè¿°ã€èŒè´£å’ŒæŠ€æœ¯é€‰æ‹©ï¼ŒåŒæ—¶æ˜ç¡®è¯´æ˜éœ€æ±‚å’Œæ¨¡å—ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚
        è¦æ±‚ï¼š
        1. æ‰€æœ‰å­—æ®µå¿…é¡»åŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦
        2. è¯·ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æ
        3. requirement_module_indexå¿…é¡»æ­£ç¡®åœ°å°†éœ€æ±‚IDæ˜ å°„åˆ°ç›¸å…³æ¨¡å—IDçš„åˆ—è¡¨
        4. æ¨¡å—åç§°åº”è¯¥åæ˜ å…¶ä¸»è¦åŠŸèƒ½
        5. æ¯ä¸ªæ¨¡å—å¿…é¡»åŒ…å«module_nameå’Œtarget_pathå­—æ®µ
        6. è¿”å›çš„JSONå¿…é¡»èƒ½å¤Ÿè¢«direct parseï¼ˆä¸è¦æœ‰markdownæ ‡è®°ï¼‰
        """.strip()
        
        # ä½¿ç”¨clarifierçš„LLMæ‰§è¡Œå™¨è°ƒç”¨LLM
        response = None
        try:
            # è·å–LLMå“åº”
            if hasattr(clarifier, 'llm_executor') and hasattr(clarifier.llm_executor, 'run_prompt'):
                print("ğŸ“ ä½¿ç”¨LLMæ‰§è¡Œå™¨è°ƒç”¨...")
                response = clarifier.llm_executor.run_prompt(user_message=prompt)
            else:
                # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                print("ğŸ“ ä½¿ç”¨Clarifier.run_llmæ–¹æ³•è°ƒç”¨...")
                response = await clarifier.run_llm(prompt=prompt)
                
            if not response:
                raise HTTPException(status_code=500, detail="æ— æ³•è·å–æœ‰æ•ˆçš„LLMå“åº”")
            
            print(f"âœ… æ”¶åˆ°LLMå“åº”: {response[:100]}...")
            
            # ä»å“åº”ä¸­æå–JSONæ•°æ®
            json_data = extract_json_from_response(response)
            
            if not json_data:
                raise HTTPException(status_code=500, detail="æ— æ³•ä»LLMå“åº”ä¸­æå–JSONæ•°æ®")
            
            print(f"âœ… æˆåŠŸè§£æJSONæ•°æ®: åŒ…å« {len(json_data.get('modules', {}))} ä¸ªæ¨¡å—")
            
            # ç¡®ä¿modulesç›®å½•å­˜åœ¨
            modules_dir = Path("data/output/modules")
            modules_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… å·²ç¡®ä¿æ¨¡å—ç›®å½•å­˜åœ¨: {modules_dir}")
            
            # ä¸ºæ¯ä¸ªæ¨¡å—åˆ›å»ºç›®å½•å’Œfull_summary.json
            modules_data = json_data.get("modules", {})
            if modules_data:
                print(f"ğŸ“ å¼€å§‹åˆ›å»ºæ¨¡å—ç›®å½•å’Œæ‘˜è¦æ–‡ä»¶...")
                for module_id, module_data in modules_data.items():
                    # ç¡®ä¿module_nameå’Œmodule_idå­—æ®µå­˜åœ¨
                    if "module_name" not in module_data:
                        module_data["module_name"] = module_data.get("name", module_id)
                    
                    module_name = module_data["module_name"]
                    module_dir = modules_dir / str(module_name)
                    module_dir.mkdir(parents=True, exist_ok=True)
                    
                    # å†™å…¥full_summary.json
                    with open(module_dir / "full_summary.json", "w", encoding="utf-8") as f:
                        json.dump(module_data, f, ensure_ascii=False, indent=2)
                    print(f"âœ… åˆ›å»ºäº†æ¨¡å—ç›®å½•å’Œæ‘˜è¦: {module_dir}")
            
            # å¦‚æœè§£ææˆåŠŸï¼Œä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_dir = Path("data/output")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            try:
                # ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœ
                with open(output_dir / "full_analysis.json", "w", encoding="utf-8") as f:
                    json.dump(json_data, f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜å®Œæ•´åˆ†æç»“æœåˆ°: {output_dir / 'full_analysis.json'}")
                
                # å•ç‹¬ä¿å­˜éœ€æ±‚
                with open(output_dir / "requirements.json", "w", encoding="utf-8") as f:
                    json.dump(json_data.get("requirements", {}), f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜éœ€æ±‚åˆ°: {output_dir / 'requirements.json'}")
                
                # å•ç‹¬ä¿å­˜æ¨¡å—
                with open(output_dir / "modules.json", "w", encoding="utf-8") as f:
                    json.dump(json_data.get("modules", {}), f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜æ¨¡å—åˆ°: {output_dir / 'modules.json'}")
                
                # ä¿å­˜ç´¢å¼•
                with open(output_dir / "requirement_module_index.json", "w", encoding="utf-8") as f:
                    json.dump(json_data.get("requirement_module_index", {}), f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜éœ€æ±‚-æ¨¡å—ç´¢å¼•åˆ°: {output_dir / 'requirement_module_index.json'}")
                
                # ç”Ÿæˆä¾èµ–å›¾
                try:
                    dependency_graph = {}
                    for module_id, module_data in modules_data.items():
                        module_name = module_data.get("module_name", "")
                        depends_on = module_data.get("dependencies", [])
                        dependency_graph[module_name] = depends_on
                    
                    with open(output_dir / "dependency_graph.py", "w", encoding="utf-8") as f:
                        f.write("# Auto-generated module dependency graph\n")
                        f.write("dependency_graph = ")
                        json.dump(dependency_graph, f, ensure_ascii=False, indent=2)
                    print(f"âœ… å·²ç”Ÿæˆä¾èµ–å›¾åˆ°: {output_dir / 'dependency_graph.py'}")
                    
                    # ç”Ÿæˆsummary_index.json
                    summary_index = {}
                    for module_id, module_data in modules_data.items():
                        module_name = module_data.get("module_name", "")
                        if module_name:
                            summary_index[module_name] = {
                                "target_path": module_data.get("target_path", ""),
                                "depends_on": module_data.get("dependencies", []),
                                "responsibilities": module_data.get("responsibilities", [])
                            }
                    
                    with open(output_dir / "summary_index.json", "w", encoding="utf-8") as f:
                        json.dump(summary_index, f, ensure_ascii=False, indent=2)
                    print(f"âœ… å·²ç”Ÿæˆsummary_index.json: {output_dir / 'summary_index.json'}")
                    
                except Exception as e:
                    print(f"âš ï¸ ç”Ÿæˆä¾èµ–å›¾æˆ–ç´¢å¼•æ—¶å‡ºé”™: {e}")
                
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜åˆ†æç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            # æ›´æ–°å…¨å±€çŠ¶æ€å¹¶è¿›è¡Œæ¶æ„éªŒè¯
            update_global_state_from_json(json_data)
            
            # ä½¿ç”¨ArchitectureManagerè¿›è¡Œæ¨¡å—å¤„ç†
            if clarifier and hasattr(clarifier, 'architecture_manager'):
                arch_manager = clarifier.architecture_manager
                for module_id, module_data in modules_data.items():
                    # è·å–å…³è”çš„éœ€æ±‚
                    requirements = []
                    for req_id, modules in json_data.get("requirement_module_index", {}).items():
                        if module_id in modules:
                            requirements.append(req_id)
                    
                    # å¤„ç†æ¨¡å—
                    print(f"ğŸ“Š å¤„ç†æ¨¡å—: {module_id}")
                    result = await arch_manager.process_new_module(module_data, requirements)
                    print(f"ğŸ” æ¨¡å—å¤„ç†ç»“æœ: {result.get('status')}")
            
            # æ·»åŠ ç”¨æˆ·å’Œç³»ç»Ÿæ¶ˆæ¯åˆ°å¯¹è¯å†å²
            user_message = {
                "role": "user",
                "content": "è¯·åˆ†ææˆ‘ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ã€‚"
            }
            
            # ç»Ÿè®¡æ¨¡å—å’Œéœ€æ±‚æ•°é‡
            req_count = len(global_state['requirements'])
            module_count = len(global_state['modules'])
            tech_stack = []
            for category in global_state['technology_stack'].values():
                if isinstance(category, list):
                    tech_stack.extend(category)
            
            system_response = {
                "role": "system",
                "content": f"æ–‡æ¡£åˆ†æå®Œæˆï¼Œå·²æå–åˆ°ä»¥ä¸‹ä¿¡æ¯:\n" +
                           f"- éœ€æ±‚æ•°é‡: {req_count}\n" +
                           f"- æ¨¡å—æ•°é‡: {module_count}\n" +
                           f"- æŠ€æœ¯æ ˆ: {', '.join(tech_stack)}\n" +
                           f"- æ¨¡å—ç›®å½•å·²ç”Ÿæˆåœ¨: data/output/modules/\n" +
                           (f"- éªŒè¯é—®é¢˜: {global_state.get('validation_issues', {})}" if global_state.get('validation_issues') else "")
            }
            
            # æ·»åŠ å®Œæˆåˆ†æåçš„æ·±åº¦æ¨ç†å¼•å¯¼æ¶ˆæ¯
            clarifier_next_steps = {
                "role": "clarifier",
                "content": "æ–‡æ¡£åˆ†æå·²å®Œæˆï¼Œç°åœ¨æ‚¨å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ“ä½œ:\n\n" + 
                          "1. è¿›è¡Œæ·±åº¦éœ€æ±‚æ¾„æ¸…ï¼Œå¸®åŠ©å®Œå–„éœ€æ±‚ç»†èŠ‚\n" +
                          "2. è¿›è¡Œæ·±åº¦æ¶æ„æ¨ç†ï¼Œç”Ÿæˆæ›´è¯¦ç»†çš„æ¶æ„è®¾è®¡\n\n" +
                          "è¯·è¾“å…¥é€‰é¡¹çš„ç¼–å·(1æˆ–2)ç»§ç»­ï¼Œæˆ–è¾“å…¥å…¶ä»–é—®é¢˜ã€‚"
            }
            
            conversation_history.append(user_message)
            conversation_history.append(system_response)
            conversation_history.append(clarifier_next_steps)
            
            return {"status": "success", "message": "æ–‡æ¡£åˆ†æå®Œæˆ", "global_state": global_state}
            
        except Exception as e:
            error_message = f"åˆ†ææ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"
            print(error_message)
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=error_message)
    
    except Exception as e:
        error_message = f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"
        print(error_message)
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=error_message)

# æ›´æ–°éœ€æ±‚
@app.post("/api/update_requirement/{req_id}")
async def update_requirement(req_id: str, data: Dict[str, Any]):
    global global_state
    
    if req_id not in global_state["requirements"]:
        raise HTTPException(status_code=404, detail=f"Requirement {req_id} not found")
    
    # Update the requirement
    global_state["requirements"][req_id].update(data)
    
    # Find affected modules (in a real implementation, this would trigger regeneration)
    affected_modules = []
    for module_id, module_data in global_state["requirement_module_index"].items():
        if "requirements" in module_data and req_id in module_data["requirements"]:
            affected_modules.append(module_id)
    
    # In a real implementation, you would regenerate these modules
    # For now, just return them
    return {
        "status": "success", 
        "requirement": global_state["requirements"][req_id],
        "affected_modules": affected_modules
    }

# åˆ†æéœ€æ±‚å¹¶ç”Ÿæˆæ¶æ„
@app.post("/api/analyze")
async def analyze_requirements():
    try:
        return await clarifier_service.analyze_architecture()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# å‘é€æ¶ˆæ¯
@app.post("/api/chat")
async def chat(message: Message):
    global clarifier, conversation_history, current_mode, global_state, uploaded_files
    
    # Initialize clarifier if needed
    if clarifier is None:
        print("âš ï¸ Clarifieræœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
        await start_clarifier()
    
    # Add user message to history
    user_message = message.content.strip()
    print(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: '{user_message}'")
    
    conversation_history.append({
        "role": "user",
        "content": user_message
    })
    
    # æ–‡æ¡£åˆ†æå®Œæˆåçš„æ·±åº¦æ¾„æ¸…å’Œæ¶æ„æ¨ç†å¿«æ·è§¦å‘
    if len(conversation_history) >= 2:
        prev_message = conversation_history[-2]
        if prev_message["role"] == "clarifier" and "æ·±åº¦æ¾„æ¸…" in prev_message["content"] and "æ·±åº¦æ¨ç†" in prev_message["content"]:
            print(f"ğŸ” æ£€æµ‹åˆ°æ·±åº¦åˆ†æé€‰é¡¹æç¤ºï¼Œç”¨æˆ·è¾“å…¥: '{user_message}'")
            
            if user_message == "1":
                # è§¦å‘æ·±åº¦æ¾„æ¸…
                print("ğŸ“Š ç”¨æˆ·é€‰æ‹©äº†æ·±åº¦æ¾„æ¸…")
                conversation_history.append({
                    "role": "system",
                    "content": "æ­£åœ¨è§¦å‘æ·±åº¦æ¾„æ¸…..."
                })
                try:
                    await deep_clarification()
                    return {"status": "success", "message": "Deep clarification triggered"}
                except Exception as e:
                    print(f"âŒ æ·±åº¦æ¾„æ¸…å‡ºé”™: {str(e)}")
                    conversation_history.append({
                        "role": "system",
                        "content": f"è§¦å‘æ·±åº¦æ¾„æ¸…æ—¶å‡ºé”™: {str(e)}"
                    })
                    return {"status": "error", "message": str(e)}
            
            elif user_message == "2":
                # è§¦å‘æ·±åº¦æ¨ç†
                print("ğŸ—ï¸ ç”¨æˆ·é€‰æ‹©äº†æ·±åº¦æ¨ç†")
                conversation_history.append({
                    "role": "system",
                    "content": "æ­£åœ¨è§¦å‘æ·±åº¦æ¶æ„æ¨ç†..."
                })
                try:
                    print("ğŸ”„ è°ƒç”¨deep_reasoningå‡½æ•°")
                    result = await deep_reasoning()
                    print(f"âœ… æ·±åº¦æ¨ç†å®Œæˆï¼Œç»“æœ: {result}")
                    return {"status": "success", "message": "Deep reasoning triggered"}
                except Exception as e:
                    print(f"âŒ è§¦å‘æ·±åº¦æ¨ç†æ—¶å‡ºé”™: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    conversation_history.append({
                        "role": "system",
                        "content": f"è§¦å‘æ·±åº¦æ¶æ„æ¨ç†æ—¶å‡ºé”™: {str(e)}"
                    })
                    return {"status": "error", "message": str(e)}
    
    # Handle mode selection if not set
    if current_mode is None:
        if user_message == "1":
            current_mode = "file_based"
            conversation_history.append({
                "role": "clarifier",
                "content": "æ‚¨é€‰æ‹©äº†åŸºäºæ–‡ä»¶åˆ†ææ¨¡å¼ã€‚è¯·ä¸Šä¼ éœ€æ±‚æ–‡æ¡£ï¼ˆ.mdæ ¼å¼ï¼‰ã€‚"
            })
            return {"status": "success", "mode": current_mode}
        elif user_message == "2":
            current_mode = "interactive"
            conversation_history.append({
                "role": "clarifier",
                "content": "æ‚¨é€‰æ‹©äº†äº¤äº’å¼å¯¹è¯æ¨¡å¼ã€‚è¯·æè¿°æ‚¨çš„ä¸šåŠ¡éœ€æ±‚ï¼Œæˆ‘å°†å¸®åŠ©æ‚¨æ¾„æ¸…éœ€æ±‚å¹¶ç”Ÿæˆæ¶æ„å»ºè®®ã€‚"
            })
            return {"status": "success", "mode": current_mode}
    
    # Process the message based on current mode
    if current_mode == "file_based":
        # In file-based mode, just acknowledge messages unless files need to be processed
        if len(uploaded_files) > 0 and user_message.upper() == "Y":
            # Handle file analysis confirmation
            return await analyze_documents()
        else:
            conversation_history.append({
                "role": "clarifier",
                "content": "è¯·ä¸Šä¼ éœ€æ±‚æ–‡æ¡£ï¼ˆ.mdæ ¼å¼ï¼‰æˆ–è¾“å…¥Yå¼€å§‹åˆ†æå·²ä¸Šä¼ çš„æ–‡æ¡£ã€‚"
            })
    else:
        # Interactive mode - process with clarifier
        if clarifier:
            try:
                # Run the clarifier with the user's message
                clarifier_response = clarifier.run_llm(
                    user_message=user_message,
                    system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆå’Œæ¶æ„è®¾è®¡å¸ˆï¼Œå¸®åŠ©ç”¨æˆ·æ¾„æ¸…ä¸šåŠ¡éœ€æ±‚å¹¶è®¾è®¡åˆé€‚çš„æ¶æ„ã€‚"
                )
                
                # Update the global state if there's structured data from clarifier
                # This would be where you process and update modules, requirements, etc.
                parse_and_update_global_state(clarifier_response)
                
                # Add the response to conversation history
                conversation_history.append({
                    "role": "clarifier",
                    "content": clarifier_response
                })
            except Exception as e:
                conversation_history.append({
                    "role": "system",
                    "content": f"å¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
                })
    
    return {"status": "success"}

def parse_and_update_global_state(response: str):
    """Parse the clarifier response and update global state if it contains structured data."""
    global global_state
    
    # Look for JSON blocks in the response
    try:
        # Very simple JSON extraction - in production would need more robust parsing
        if "```json" in response and "```" in response:
            json_content = response.split("```json")[1].split("```")[0].strip()
            data = json.loads(json_content)
            
            # Update global state with extracted data
            if "requirements" in data:
                global_state["requirements"].update(data["requirements"])
            if "modules" in data:
                global_state["modules"] = data["modules"]
            if "technology_stack" in data:
                global_state["technology_stack"] = data["technology_stack"]
            if "requirement_module_index" in data:
                global_state["requirement_module_index"] = data["requirement_module_index"]
            if "architecture_pattern" in data:
                global_state["architecture_pattern"] = data["architecture_pattern"]
    except Exception as e:
        print(f"Error parsing JSON from response: {e}")

# æ›´æ–°process_fileså‡½æ•°ä½¿å…¶è°ƒç”¨analyze_documents
async def process_files():
    """Process the uploaded files using the clarifier."""
    # ç›´æ¥è°ƒç”¨analyze_documentså‡½æ•°å¤„ç†æ–‡ä»¶
    return await analyze_documents()

# å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    # è‡ªåŠ¨åˆå§‹åŒ–ç³»ç»Ÿ
    clarifier_service.add_system_message("ç³»ç»Ÿå¯åŠ¨ä¸­ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        await clarifier_service.initialize()
    except Exception as e:
        clarifier_service.add_system_message(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")

# ä¿®æ”¹æ·±åº¦æ¾„æ¸…APIä»¥è°ƒç”¨Clarifierç±»ä¸­çš„æ–¹æ³•
@app.post("/api/deep_clarification")
async def deep_clarification():
    global clarifier, conversation_history, global_state
    
    if not clarifier:
        raise HTTPException(status_code=400, detail="Clarifier not initialized")
    
    try:
        conversation_history.append({
            "role": "system",
            "content": "å¼€å§‹è¿›è¡Œæ·±åº¦éœ€æ±‚æ¾„æ¸…..."
        })
        
        # æ„å»ºéœ€æ±‚æ•°æ®
        requirement_analysis = {
            "requirements": [],
            "system_overview": {},
            "functional_requirements": {}
        }
        
        # ä»å…¨å±€çŠ¶æ€ä¸­è·å–éœ€æ±‚æ•°æ®
        if global_state["requirements"]:
            for req_id, req_data in global_state["requirements"].items():
                requirement_analysis["requirements"].append(req_data)
        
        # è°ƒç”¨Clarifieræ ¸å¿ƒç±»çš„æ·±åº¦æ¾„æ¸…æ–¹æ³•
        result = await clarifier.deep_clarification(requirement_analysis)
        
        # å¦‚æœæ²¡æœ‰å¾—åˆ°ç»“æœï¼Œå¯èƒ½æ˜¯å› ä¸ºéœ€æ±‚æ•°æ®ä¸è¶³
        if not result or not result.get("clarification_result"):
            conversation_history.append({
                "role": "system",
                "content": "æ·±åº¦æ¾„æ¸…æœªè¿”å›ç»“æœï¼Œå¯èƒ½æ˜¯å› ä¸ºéœ€æ±‚æ•°æ®ä¸è¶³ã€‚"
            })
            return {"status": "warning", "message": "No clarification result returned"}
        
        # æ·»åŠ ç»“æœåˆ°å¯¹è¯å†å²
        conversation_history.append({
            "role": "clarifier", 
            "content": result.get("clarification_result", "æ·±åº¦æ¾„æ¸…å®Œæˆï¼Œä½†æ²¡æœ‰å…·ä½“ç»“æœã€‚")
        })
        
        return {"status": "success", "message": "Deep clarification completed"}
    
    except Exception as e:
        conversation_history.append({
            "role": "system",
            "content": f"æ·±åº¦æ¾„æ¸…æ—¶å‡ºé”™: {str(e)}"
        })
        raise HTTPException(status_code=500, detail=str(e))

# ä¿®æ”¹æ·±åº¦æ¨ç†APIä»¥è°ƒç”¨Clarifierç±»ä¸­çš„æ–¹æ³•ï¼Œå¹¶å¢åŠ è¯¦ç»†çš„æ—¥å¿—
@app.post("/api/deep_reasoning")
async def deep_reasoning():
    global clarifier, conversation_history, global_state
    
    if not clarifier:
        print("âŒ æ·±åº¦æ¨ç†å¤±è´¥: Clarifieræœªåˆå§‹åŒ–")
        raise HTTPException(status_code=400, detail="Clarifier not initialized")
    
    try:
        print("ğŸ” å¼€å§‹è¿›è¡Œæ·±åº¦æ¶æ„æ¨ç†...")
        conversation_history.append({
            "role": "system",
            "content": "å¼€å§‹è¿›è¡Œæ·±åº¦æ¶æ„æ¨ç†..."
        })
        
        # æ„å»ºéœ€æ±‚å’Œæ¶æ„æ•°æ®
        requirement_analysis = {
            "requirements": [],
            "system_overview": {},
            "functional_requirements": {}
        }
        
        architecture_analysis = {
            "modules": [],
            "architecture_pattern": {},
            "technology_stack": {}
        }
        
        # ä»å…¨å±€çŠ¶æ€ä¸­è·å–éœ€æ±‚æ•°æ®
        if global_state["requirements"]:
            print(f"ğŸ“Š æ‰¾åˆ° {len(global_state['requirements'])} ä¸ªéœ€æ±‚")
            for req_id, req_data in global_state["requirements"].items():
                requirement_analysis["requirements"].append(req_data)
                print(f"  - éœ€æ±‚: {req_data.get('name', req_id)}")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€æ±‚æ•°æ®")
        
        # ä»å…¨å±€çŠ¶æ€ä¸­è·å–æ¶æ„æ•°æ®
        if global_state["modules"]:
            print(f"ğŸ“Š æ‰¾åˆ° {len(global_state['modules'])} ä¸ªæ¨¡å—")
            for module_id, module_data in global_state["modules"].items():
                architecture_analysis["modules"].append(module_data)
                print(f"  - æ¨¡å—: {module_data.get('name', module_id)}")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¨¡å—æ•°æ®")
        
        architecture_analysis["architecture_pattern"] = global_state["architecture_pattern"]
        architecture_analysis["technology_stack"] = global_state["technology_stack"]
        
        print("ğŸ”„ è°ƒç”¨Clarifier.deep_reasoning...")
        
        # è°ƒç”¨Clarifieræ ¸å¿ƒç±»çš„æ·±åº¦æ¨ç†æ–¹æ³•
        result = await clarifier.deep_reasoning(requirement_analysis, architecture_analysis)
        
        print(f"âœ… æ·±åº¦æ¨ç†å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")
        
        # å¦‚æœæ²¡æœ‰å¾—åˆ°ç»“æœï¼Œå¯èƒ½æ˜¯å› ä¸ºæ•°æ®ä¸è¶³
        if not result:
            print("âš ï¸ æ·±åº¦æ¨ç†æœªè¿”å›ä»»ä½•ç»“æœ")
            conversation_history.append({
                "role": "system",
                "content": "æ·±åº¦æ¨ç†æœªè¿”å›ç»“æœï¼Œå¯èƒ½æ˜¯å› ä¸ºéœ€æ±‚æˆ–æ¶æ„æ•°æ®ä¸è¶³ã€‚"
            })
            return {"status": "warning", "message": "No reasoning result returned"}
        
        if not result.get("reasoning_result"):
            print("âš ï¸ æ·±åº¦æ¨ç†è¿”å›çš„ç»“æœä¸­æ²¡æœ‰reasoning_resultå­—æ®µ")
            conversation_history.append({
                "role": "system",
                "content": "æ·±åº¦æ¨ç†æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œå¯èƒ½æ˜¯å› ä¸ºéœ€æ±‚æˆ–æ¶æ„æ•°æ®ä¸è¶³ã€‚"
            })
            return {"status": "warning", "message": "No valid reasoning result returned"}
        
        reasoning_content = result.get("reasoning_result", "")
        print(f"ğŸ“ ç»“æœé•¿åº¦: {len(reasoning_content)} å­—ç¬¦")
        
        # å°è¯•ä»å“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®
        print("ğŸ” ä»å“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®...")
        extracted_json = extract_json_from_response(reasoning_content)
        
        if extracted_json:
            print(f"âœ… æˆåŠŸä»æ¨ç†ç»“æœä¸­æå–JSONæ•°æ®")
            # æ›´æ–°å…¨å±€çŠ¶æ€
            update_global_state_from_json(extracted_json)
            
            # å°è¯•è¯†åˆ«æ–°æ¨¡å—
            if "modules" in extracted_json:
                new_modules_count = 0
                for module_id, module_data in extracted_json["modules"].items():
                    if module_id not in global_state["modules"]:
                        new_modules_count += 1
                        
                if new_modules_count > 0:
                    print(f"ğŸ” ä»æ¨ç†ä¸­è¯†åˆ«åˆ° {new_modules_count} ä¸ªæ–°æ¨¡å—")
                    conversation_history.append({
                        "role": "system",
                        "content": f"æ·±åº¦æ¨ç†å‘ç° {new_modules_count} ä¸ªæ–°æ¨¡å—ã€‚è¿™äº›æ¨¡å—å·²æ·»åŠ åˆ°æ¶æ„ä¸­ã€‚"
                    })
            
            # å°è¯•è¯†åˆ«å¾ªç¯ä¾èµ–
            try:
                if clarifier and hasattr(clarifier, 'architecture_manager'):
                    arch_manager = clarifier.architecture_manager
                    if hasattr(arch_manager, 'find_circular_dependencies'):
                        circular_deps = arch_manager.find_circular_dependencies()
                        if circular_deps:
                            print(f"âš ï¸ æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {circular_deps}")
                            conversation_history.append({
                                "role": "system",
                                "content": f"è­¦å‘Šï¼šæ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {', '.join([' -> '.join(dep) for dep in circular_deps])}"
                            })
            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥å¾ªç¯ä¾èµ–æ—¶å‡ºé”™: {e}")
        else:
            print("âš ï¸ æ— æ³•ä»æ¨ç†ç»“æœä¸­æå–JSONæ•°æ®ï¼Œä»…ä¿å­˜æ–‡æœ¬å†…å®¹")
            parse_and_update_global_state(reasoning_content)
        
        # ä¿å­˜æ¨ç†ç»“æœåˆ°æ–‡ä»¶
        try:
            output_dir = Path("data/output")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ä¸ºMarkdownæ–‡æ¡£
            with open(output_dir / "deep_reasoning_result.md", "w", encoding="utf-8") as f:
                f.write(f"# æ·±åº¦æ¶æ„æ¨ç†ç»“æœ\n\n{reasoning_content}")
            print(f"âœ… å·²ä¿å­˜æ¨ç†ç»“æœåˆ°: {output_dir / 'deep_reasoning_result.md'}")
            
            # å¦‚æœæå–åˆ°äº†JSONï¼Œä¹Ÿå•ç‹¬ä¿å­˜
            if extracted_json:
                with open(output_dir / "deep_reasoning_result.json", "w", encoding="utf-8") as f:
                    json.dump(extracted_json, f, ensure_ascii=False, indent=2)
                print(f"âœ… å·²ä¿å­˜ç»“æ„åŒ–æ¨ç†ç»“æœåˆ°: {output_dir / 'deep_reasoning_result.json'}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ¨ç†ç»“æœæ—¶å‡ºé”™: {e}")
        
        # æ·»åŠ ç»“æœåˆ°å¯¹è¯å†å²
        conversation_history.append({
            "role": "clarifier", 
            "content": reasoning_content
        })
        
        # æ·»åŠ æ·±åº¦æ¨ç†å®Œæˆçš„æç¤ºæ¶ˆæ¯
        conversation_history.append({
            "role": "clarifier", 
            "content": "æ·±åº¦æ¨ç†å®Œæˆã€‚æ‚¨å¯ä»¥ï¼š\n1. æŸ¥çœ‹ç”Ÿæˆçš„æ¨¡å—è¯¦æƒ…\n2. å¼€å§‹å®ç°ä»£ç \n3. è¿›è¡Œæ¶æ„éªŒè¯"
        })
        
        return {"status": "success", "message": "Deep reasoning completed", "has_extracted_json": bool(extracted_json)}
    
    except Exception as e:
        print(f"âŒ æ·±åº¦æ¨ç†æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        
        conversation_history.append({
            "role": "system",
            "content": f"æ·±åº¦æ¨ç†æ—¶å‡ºé”™: {str(e)}"
        })
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/check_dependencies")
async def check_dependencies():
    """æ£€æŸ¥æ¨¡å—ä¾èµ–å’Œå¾ªç¯ä¾èµ–"""
    global clarifier, global_state
    
    if not clarifier:
        raise HTTPException(status_code=400, detail="Clarifierå°šæœªåˆå§‹åŒ–")
    
    try:
        if hasattr(clarifier, 'architecture_manager'):
            arch_manager = clarifier.architecture_manager
            
            from core.clarifier.architecture_reasoner import ArchitectureReasoner
            reasoner = ArchitectureReasoner(architecture_manager=arch_manager)
            
            cycles = reasoner._check_global_circular_dependencies()
            
            validation_issues = {}
            if hasattr(arch_manager, 'get_validation_issues'):
                validation_issues = arch_manager.get_validation_issues()
            
            # æ›´æ–°å…¨å±€çŠ¶æ€
            global_state["validation_issues"] = {
                "circular_dependencies": cycles,
                "module_issues": validation_issues
            }
            
            return {
                "status": "success",
                "circular_dependencies": cycles,
                "validation_issues": validation_issues
            }
        else:
            raise HTTPException(status_code=400, detail="æ¶æ„ç®¡ç†å™¨ä¸å¯ç”¨")
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ä¾èµ–æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥ä¾èµ–æ—¶å‡ºé”™: {str(e)}")

# æ›´æ–°å…¨å±€çŠ¶æ€çš„å‡½æ•°
def update_global_state_from_json(data: Dict[str, Any]) -> None:
    """ä»JSONæ•°æ®æ›´æ–°å…¨å±€çŠ¶æ€ï¼Œå¹¶ä½¿ç”¨ç°æœ‰æ¶æ„ç®¡ç†å™¨æ‰§è¡ŒéªŒè¯"""
    global global_state, clarifier
    
    print(f"ğŸ”„ å¼€å§‹ä»JSONæ›´æ–°å…¨å±€çŠ¶æ€...")
    
    # åŸºæœ¬çŠ¶æ€æ›´æ–°
    if "requirements" in data and isinstance(data["requirements"], dict):
        global_state["requirements"] = data["requirements"]
        print(f"âœ… æ›´æ–°äº† {len(data['requirements'])} ä¸ªéœ€æ±‚")
    
    if "modules" in data and isinstance(data["modules"], dict):
        global_state["modules"] = data["modules"]
        print(f"âœ… æ›´æ–°äº† {len(data['modules'])} ä¸ªæ¨¡å—")
        
        # ä¸ºæ¯ä¸ªæ¨¡å—åˆ›å»ºç›®å½•å’Œæ–‡ä»¶
        modules_dir = Path("data/output/modules")
        modules_dir.mkdir(parents=True, exist_ok=True)
        
        for module_id, module_data in data["modules"].items():
            # ç¡®ä¿module_nameå­—æ®µå­˜åœ¨
            if "module_name" not in module_data:
                module_data["module_name"] = module_data.get("name", module_id)
                
            module_name = module_data["module_name"]
            module_dir = modules_dir / str(module_name)
            module_dir.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥full_summary.json
            summary_path = module_dir / "full_summary.json"
            try:
                with open(summary_path, "w", encoding="utf-8") as f:
                    json.dump(module_data, f, ensure_ascii=False, indent=2)
                print(f"âœ… ä¸ºæ¨¡å— '{module_name}' åˆ›å»ºäº†æ‘˜è¦æ–‡ä»¶: {summary_path}")
            except Exception as e:
                print(f"âŒ ä¸ºæ¨¡å— '{module_name}' åˆ›å»ºæ‘˜è¦æ–‡ä»¶å¤±è´¥: {e}")
    
    if "technology_stack" in data and isinstance(data["technology_stack"], dict):
        global_state["technology_stack"] = data["technology_stack"]
        print(f"âœ… æ›´æ–°äº†æŠ€æœ¯æ ˆ")
    
    if "requirement_module_index" in data and isinstance(data["requirement_module_index"], dict):
        requirement_module_map = {}
        for req_id, modules in data["requirement_module_index"].items():
            req_name = data.get("requirements", {}).get(req_id, {}).get("name", "æœªçŸ¥éœ€æ±‚")
            requirement_module_map[req_id] = {
                "name": req_name,
                "modules": modules
            }
        
        global_state["requirement_module_index"] = requirement_module_map
        print(f"âœ… å·²æ›´æ–°éœ€æ±‚-æ¨¡å—æ˜ å°„å…³ç³»")
    
    if "architecture_pattern" in data and isinstance(data["architecture_pattern"], dict):
        global_state["architecture_pattern"] = data["architecture_pattern"]
        print(f"âœ… æ›´æ–°äº†æ¶æ„æ¨¡å¼")
    
    if "modules" in data and isinstance(data["modules"], dict):
        modules_data = data["modules"]
        
        responsibility_index = {}
        layer_index = {}
        domain_index = {}
        
        for module_id, module_info in modules_data.items():
            for resp in module_info.get("responsibilities", []):
                if resp not in responsibility_index:
                    responsibility_index[resp] = []
                responsibility_index[resp].append(module_id)
            
            layer = module_info.get("layer", "unknown")
            if layer not in layer_index:
                layer_index[layer] = []
            layer_index[layer].append(module_id)
            
            domain = module_info.get("domain", "unknown")
            if domain not in domain_index:
                domain_index[domain] = []
            domain_index[domain].append(module_id)
        
        global_state["responsibility_index"] = responsibility_index
        global_state["layer_index"] = layer_index
        global_state["domain_index"] = domain_index
        print(f"âœ… å·²æ›´æ–°å¤šç»´åº¦æ¨¡å—ç´¢å¼•")
    
    # å°è¯•ç”Ÿæˆä¾èµ–å›¾å’Œç´¢å¼•æ–‡ä»¶
    try:
        modules_data = data.get("modules", {})
        output_dir = Path("data/output")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆä¾èµ–å›¾
        dependency_graph = {}
        for module_id, module_data in modules_data.items():
            module_name = module_data.get("module_name", "")
            depends_on = module_data.get("dependencies", [])
            dependency_graph[module_name] = depends_on
        
        with open(output_dir / "dependency_graph.py", "w", encoding="utf-8") as f:
            f.write("# Auto-generated module dependency graph\n")
            f.write("dependency_graph = ")
            json.dump(dependency_graph, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ç”Ÿæˆä¾èµ–å›¾åˆ°: {output_dir / 'dependency_graph.py'}")
        
        # ç”Ÿæˆsummary_index.json
        summary_index = {}
        for module_id, module_data in modules_data.items():
            module_name = module_data.get("module_name", "")
            if module_name:
                summary_index[module_name] = {
                    "target_path": module_data.get("target_path", ""),
                    "depends_on": module_data.get("dependencies", []),
                    "responsibilities": module_data.get("responsibilities", [])
                }
        
        with open(output_dir / "summary_index.json", "w", encoding="utf-8") as f:
            json.dump(summary_index, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ç”Ÿæˆsummary_index.json: {output_dir / 'summary_index.json'}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆä¾èµ–å›¾æˆ–ç´¢å¼•æ—¶å‡ºé”™: {e}")
    
    # é€šè¿‡ç°æœ‰çš„ArchitectureManageréªŒè¯æ¶æ„
    try:
        # ä½¿ç”¨ç°æœ‰çš„ArchitectureManageråˆå§‹åŒ–
        if clarifier and hasattr(clarifier, 'architecture_manager'):
            arch_manager = clarifier.architecture_manager
            print(f"ğŸ” ä½¿ç”¨ArchitectureManageréªŒè¯æ¶æ„...")
            
            # 1. å…ˆæ·»åŠ æ‰€æœ‰éœ€æ±‚åˆ°æ¶æ„ç®¡ç†å™¨
            if "requirements" in data:
                for req_id, req_data in data["requirements"].items():
                    if hasattr(arch_manager, 'add_requirement'):
                        arch_manager.add_requirement(req_data)
                        print(f"âœ… æ·»åŠ éœ€æ±‚ '{req_id}' åˆ°æ¶æ„ç®¡ç†å™¨")
            
            # 2. æ·»åŠ æ¨¡å—åˆ°æ¶æ„ç´¢å¼•
            for module_id, module in global_state["modules"].items():
                # æŸ¥æ‰¾è¯¥æ¨¡å—å¯¹åº”çš„éœ€æ±‚
                requirements = []
                if "requirement_module_index" in data:
                    for req_id, modules in data["requirement_module_index"].items():
                        if module_id in modules:
                            requirements.append(req_id)
                            print(f"ğŸ“Š æ¨¡å— '{module_id}' å…³è”åˆ°éœ€æ±‚ '{req_id}'")
                
                # æ£€æŸ¥æ¨¡å—æ˜¯å¦å·²å­˜åœ¨äºç´¢å¼•ä¸­
                module_name = module.get("module_name", module_id)
                if hasattr(arch_manager.index, 'dependency_graph') and module_name not in arch_manager.index.dependency_graph:
                    print(f"ğŸ”„ æ·»åŠ æ¨¡å— '{module_name}' åˆ°æ¶æ„ç´¢å¼•...")
                    # æ·»åŠ æ¨¡å—åˆ°æ¶æ„ç´¢å¼•å¹¶ç”Ÿæˆç›®å½•
                    try:
                        if hasattr(arch_manager, 'process_new_module'):
                            process_result = arch_manager.process_new_module(module, requirements)
                            print(f"âœ… æ¨¡å—å¤„ç†ç»“æœ: {process_result.get('status', 'æœªçŸ¥')}")
                    except Exception as e:
                        print(f"âŒ å¤„ç†æ¨¡å— '{module_name}' æ—¶å‡ºé”™: {e}")
            
            # 3. ä»æ¶æ„ç®¡ç†å™¨ä¸­è·å–éªŒè¯é—®é¢˜
            try:
                if hasattr(arch_manager, 'get_validation_issues'):
                    validation_issues = arch_manager.get_validation_issues()
                    if validation_issues:
                        global_state["validation_issues"] = validation_issues
                        print(f"âš ï¸ æ£€æµ‹åˆ°æ¶æ„éªŒè¯é—®é¢˜: {validation_issues}")
            except Exception as e:
                print(f"âš ï¸ è·å–éªŒè¯é—®é¢˜æ—¶å‡ºé”™: {e}")
            
    except Exception as e:
        print(f"âš ï¸ æ¶æ„éªŒè¯å‡ºé”™: {str(e)}")
        traceback.print_exc()

# æ”¹è¿›JSONæå–å‡½æ•°
def extract_json_from_response(response: str) -> Dict[str, Any]:
    """ä»LLMå“åº”ä¸­æå–JSONæ•°æ®ï¼Œå¢å¼ºæå–èƒ½åŠ›"""
    if not response:
        return {}
    
    # å¯»æ‰¾JSONå— - æ”¯æŒå¤šç§æ ‡è®°æ–¹å¼
    json_patterns = [
        r'```(?:json)?(.*?)```',  # æ ‡å‡†markdownä»£ç å—
        r'{[\s\S]*"requirements"[\s\S]*}',  # ç›´æ¥æŸ¥æ‰¾åŒ…å«requirementsçš„JSONå¯¹è±¡
        r'{[\s\S]*"modules"[\s\S]*}',       # ç›´æ¥æŸ¥æ‰¾åŒ…å«modulesçš„JSONå¯¹è±¡
    ]
    
    # å°è¯•æ‰€æœ‰æ¨¡å¼
    for pattern in json_patterns:
        matches = re.findall(pattern, response, re.DOTALL)
        if matches:
            # å°è¯•è§£æåŒ¹é…çš„JSONå—
            for match in matches:
                try:
                    # æ¸…ç†JSONæ–‡æœ¬
                    cleaned_json = match.strip()
                    return json.loads(cleaned_json)
                except json.JSONDecodeError:
                    print(f"âš ï¸ JSONè§£æé”™è¯¯ï¼Œå°è¯•æ¸…ç†JSONæ–‡æœ¬")
                    try:
                        # ç§»é™¤æ³¨é‡Šè¡Œ
                        no_comments = re.sub(r'^\s*//.*$', '', cleaned_json, flags=re.MULTILINE)
                        # ç§»é™¤å°¾éƒ¨é€—å·
                        fixed_commas = re.sub(r',\s*}', '}', no_comments)
                        fixed_commas = re.sub(r',\s*]', ']', fixed_commas)
                        return json.loads(fixed_commas)
                    except json.JSONDecodeError:
                        continue  # å°è¯•ä¸‹ä¸€ä¸ªåŒ¹é…é¡¹
    
    # å°è¯•ç›´æ¥ä»æ–‡æœ¬ä¸­æå–JSON (å¦‚æœæ•´ä¸ªå“åº”å°±æ˜¯ä¸€ä¸ªJSON)
    try:
        return json.loads(response)
    except json.JSONDecodeError:
        pass
    
    # æœ€åå°è¯•å¯»æ‰¾å¤§æ‹¬å·åŒ…å›´çš„å†…å®¹
    try:
        # æŸ¥æ‰¾æœ€å¤–å±‚çš„å¤§æ‹¬å·
        curly_pattern = r'{[\s\S]*}'
        match = re.search(curly_pattern, response, re.DOTALL)
        if match:
            return json.loads(match.group(0))
    except json.JSONDecodeError:
        pass
    
    print("âš ï¸ æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSON")
    return {}

# ä¸»å‡½æ•°
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("webui.app:app", host="0.0.0.0", port=8080, reload=True)                        