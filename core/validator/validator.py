import json
import asyncio
from pathlib import Path
from core.llm.llm_executor import run_prompt, split_text_by_tokens
from core.llm.chat_openai import chat
import tiktoken
from dependency_manager import DependencyManager
import re
import time
from prompt_templates import get_validator_prompt as get_template_prompt
from architecture.module_validator import is_valid_module_name, validate_module_dependencies
import copy

def get_validator_prompt(i, total, boundary_analysis=None):
    """ä»prompt_templatesåº“ä¸­è·å–éªŒè¯å™¨prompt"""
    return get_template_prompt(i + 1, total, boundary_analysis)

def parse_json_response(text: str) -> dict:
    """è§£æLLMè¿”å›çš„JSONå“åº”ï¼Œå¤„ç†å„ç§å¸¸è§çš„æ ¼å¼é—®é¢˜
    
    å¢å¼ºç‰ˆæœ¬: å¤„ç†æ›´å¤šè¾¹ç¼˜æƒ…å†µï¼Œç¡®ä¿æœ‰æ•ˆJSON
    """
    if not text:
        return {}
    
    # è®°å½•åŸå§‹æ–‡æœ¬ä»¥ä¾¿è°ƒè¯•
    original_text = text
    
    # 1. æ¸…ç†æ–‡æœ¬
    text = text.strip()
    
    # 2. ç§»é™¤markdownä»£ç å—æ ‡è®°
    code_block_pattern = r'```(?:json|javascript|js|JSON)?(.+?)```'
    matches = re.findall(code_block_pattern, text, re.DOTALL)
    if matches:
        # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªä»£ç å—å†…å®¹
        text = matches[0].strip()
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—ï¼Œä¹Ÿå¤„ç†å¯èƒ½çš„å•è¡Œä»£ç æ ‡è®°
        if text.startswith('```'):
            text = text[text.find('\n')+1:]
        if text.endswith('```'):
            text = text[:text.rfind('```')]
        text = text.strip()
    
    # 3. å°è¯•ç›´æ¥è§£æJSON
    try:
        parsed = json.loads(text)
        return parsed
    except json.JSONDecodeError:
        print(f"âš ï¸ åˆæ¬¡JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤æ ¼å¼é—®é¢˜...")
    
    # 4. æŸ¥æ‰¾å¹¶æå–æœ€å¤–å±‚çš„JSONå¯¹è±¡
    try:
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
        start_idx = text.find('{')
        end_idx = text.rfind('}')
        if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
            extracted_text = text[start_idx:end_idx+1]
            try:
                return json.loads(extracted_text)
            except:
                print(f"âš ï¸ æå–JSONå¯¹è±¡åä»ç„¶æ— æ³•è§£æ")
    except Exception as e:
        print(f"âš ï¸ æå–JSONå¤±è´¥: {e}")
    
    # 5. å°è¯•ä¿®å¤å¸¸è§çš„JSONè¯­æ³•é—®é¢˜
    try:
        # 5.1 å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·ï¼ˆJavaScripté£æ ¼ -> JSONï¼‰
        fixed_text = re.sub(r"'([^']*)':", r'"\1":', text)
        # 5.2 ç»™æ²¡æœ‰å¼•å·çš„é”®æ·»åŠ å¼•å·
        fixed_text = re.sub(r'([{,])\s*([a-zA-Z0-9_]+):', r'\1"\2":', fixed_text)
        # 5.3 åˆ é™¤ç»“å°¾çš„é€—å·
        fixed_text = re.sub(r',\s*}', '}', fixed_text)
        fixed_text = re.sub(r',\s*]', ']', fixed_text)
        
        try:
            parsed = json.loads(fixed_text)
            print("âœ… æˆåŠŸé€šè¿‡ä¿®å¤JSONè¯­æ³•è§£æ")
            return parsed
        except:
            print("âš ï¸ ä¿®å¤JSONè¯­æ³•åä»ç„¶æ— æ³•è§£æ")
    except Exception as e:
        print(f"âš ï¸ ä¿®å¤JSONè¯­æ³•æ—¶å‡ºé”™: {e}")
    
    # 6. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å°è¯•æ„å»ºJSONå¯¹è±¡
    try:
        # å°è¯•æå–æ‰€æœ‰é”®å€¼å¯¹
        pairs = re.findall(r'"([^"]+)"\s*:\s*("([^"\\]*(\\.[^"\\]*)*)"|\[.*?\]|{.*?}|true|false|null|-?\d+(\.\d+)?)', text)
        if pairs:
            json_obj = {}
            for pair in pairs:
                key = pair[0]
                value = pair[1]
                
                # å¤„ç†å­—ç¬¦ä¸²å€¼
                if value.startswith('"') and value.endswith('"'):
                    json_obj[key] = value[1:-1]
                # å¤„ç†æ•°ç»„å€¼
                elif value.startswith('[') and value.endswith(']'):
                    try:
                        json_obj[key] = json.loads(value)
                    except:
                        json_obj[key] = []
                # å¤„ç†å¯¹è±¡å€¼
                elif value.startswith('{') and value.endswith('}'):
                    try:
                        json_obj[key] = json.loads(value)
                    except:
                        json_obj[key] = {}
                # å¤„ç†å¸ƒå°”å€¼å’Œnull
                elif value in ['true', 'false', 'null']:
                    json_obj[key] = json.loads(value)
                # å¤„ç†æ•°å­—
                else:
                    try:
                        json_obj[key] = float(value) if '.' in value else int(value)
                    except:
                        json_obj[key] = value
            
            if json_obj:
                print("âœ… æˆåŠŸé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æ„å»ºJSONå¯¹è±¡")
                return json_obj
    except Exception as e:
        print(f"âš ï¸ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ„å»ºJSONæ—¶å‡ºé”™: {e}")
    
    # 7. æœ€åå°è¯•ï¼šå¦‚æœå®Œå…¨æ— æ³•è§£æï¼Œè¿”å›éƒ¨åˆ†ç»“æ„åŒ–æ•°æ®
    print(f"âŒ æ‰€æœ‰è§£ææ–¹æ³•å‡å¤±è´¥ï¼Œè¿”å›ç©ºå¯¹è±¡")
    print(f"åŸå§‹æ–‡æœ¬çš„å‰200ä¸ªå­—ç¬¦: {original_text[:200]}")
    return {}

def custom_merge_sections(acc, current):
    """ç®€å•æ”¶é›†ç»“æœç”¨äºè°ƒè¯•
    
    Args:
        acc: ç´¯ç§¯çš„ç»“æœ
        current: å½“å‰éœ€è¦åˆå¹¶çš„ç»“æœ
        
    Returns:
        åˆå¹¶åçš„ç»“æœ
    """
    # æ”¶é›†ç»“æœç”¨äºè°ƒè¯•
    if not hasattr(custom_merge_sections, 'all_results'):
        custom_merge_sections.all_results = []
    
    if current:
        custom_merge_sections.all_results.append(current)
    
    # æ€»æ˜¯è¿”å›ç¬¬ä¸€ä¸ªæœ‰æ•ˆç»“æœ
    return current if not acc else acc

def check_module_structure(summary: dict, summary_index: dict, issues: dict):
    """æ£€æŸ¥æ¨¡å—çš„ç»“æ„æ€§é—®é¢˜ï¼Œæ›´åŠ å®¹é”™"""
    name = summary.get("module_name", "<unknown>")
    problems = []

    # ä½¿ç”¨module_validatoréªŒè¯æ¨¡å—åç§°
    is_valid, error = is_valid_module_name(name)
    if not is_valid:
        problems.append(f"invalid module name: {error}")

    # æ£€æŸ¥èŒè´£
    if not summary.get("responsibilities"):
        problems.append("missing responsibilities")
    elif isinstance(summary["responsibilities"], list) and len(summary["responsibilities"]) < 2:
        problems.append("too few responsibilities")
    elif not isinstance(summary["responsibilities"], list):
        problems.append("responsibilities should be an array")

    # æ£€æŸ¥API
    if not summary.get("key_apis"):
        problems.append("missing key_apis")
    elif not isinstance(summary["key_apis"], list):
        problems.append("key_apis should be an array")

    # æ£€æŸ¥æ•°æ®è¾“å…¥è¾“å‡º
    if not summary.get("data_inputs"):
        problems.append("missing data_inputs")
    elif not isinstance(summary["data_inputs"], list):
        problems.append("data_inputs should be an array")

    if not summary.get("data_outputs"):
        problems.append("missing data_outputs")
    elif not isinstance(summary["data_outputs"], list):
        problems.append("data_outputs should be an array")

    # æ£€æŸ¥ç›®æ ‡è·¯å¾„
    if not summary.get("target_path"):
        problems.append("missing target_path")
    
    # æ£€æŸ¥ä¾èµ–
    depends_on = summary.get("depends_on", [])
    if not isinstance(depends_on, list):
        problems.append("depends_on should be an array")
        # å°è¯•è½¬æ¢éåˆ—è¡¨ä¾èµ–ä¸ºåˆ—è¡¨
        try:
            if isinstance(depends_on, str):
                depends_on = [depends_on]
        except:
            depends_on = []
    
    # ä½¿ç”¨module_validatoréªŒè¯ä¾èµ–å…³ç³»
    if isinstance(depends_on, list) and name and len(depends_on) > 0:
        dependency_errors = validate_module_dependencies(name, depends_on)
        if dependency_errors:
            problems.extend(dependency_errors)
    
    # æ£€æŸ¥æœªå®šä¹‰ä¾èµ–
    for dep in depends_on:
        if dep and dep not in summary_index and dep != name:  # é¿å…è‡ªä¾èµ–
            problems.append(f"undefined dependency: {dep}")

    if problems:
        issues[name] = problems
    
    return len(problems) == 0  # è¿”å›æ˜¯å¦æ£€æŸ¥é€šè¿‡

def analyze_module_boundaries(summaries, dependency_manager):
    """åˆ†ææ¨¡å—è¾¹ç•Œå’Œåˆå¹¶å»ºè®®ï¼Œå¢åŠ å®¹é”™å¤„ç†"""
    merge_suggestions = []
    split_suggestions = []
    
    try:
        # åˆ†æå¯èƒ½éœ€è¦åˆå¹¶çš„æ¨¡å—ï¼ˆåŸºäºå‘½åç›¸ä¼¼æ€§ï¼‰
        name_patterns = {}
        for summary in summaries:
            name = summary.get("module_name", "")
            if not name:
                continue
                
            # æå–åŸºæœ¬åç§°ï¼ˆå»æ‰Controllerã€Serviceã€Repositoryç­‰åç¼€ï¼‰
            base_name = re.sub(r'(Controller|Service|Repository|Page|Model)$', '', name)
            if base_name not in name_patterns:
                name_patterns[base_name] = []
            name_patterns[base_name].append(name)
        
        for base, modules in name_patterns.items():
            if len(modules) > 1:
                # æ£€æŸ¥è¿™äº›æ¨¡å—æ˜¯å¦æœ‰é‡å èŒè´£
                module_map = {m: next((s for s in summaries if s.get("module_name") == m), {}) for m in modules}
                responsibilities = {}
                for m, data in module_map.items():
                    for resp in data.get("responsibilities", []):
                        if not resp:
                            continue
                        resp_key = resp.lower()
                        if resp_key not in responsibilities:
                            responsibilities[resp_key] = []
                        responsibilities[resp_key].append(m)
                
                overlapping = [r for r, ms in responsibilities.items() if len(ms) > 1]
                if overlapping:
                    merge_suggestions.append({
                        "modules": modules,
                        "reason": f"å‘½åç›¸ä¼¼ä¸”èŒè´£é‡å : {', '.join(overlapping[:3])}"
                    })
        
        # æ£€æŸ¥å¾ªç¯ä¾èµ–ï¼Œå¯èƒ½éœ€è¦åˆå¹¶
        cycles = dependency_manager.check_circular_dependencies()
        if cycles["has_cycles"]:
            for cycle in cycles["cycles"]:
                if len(cycle) > 1:
                    merge_suggestions.append({
                        "modules": cycle,
                        "reason": f"å­˜åœ¨å¾ªç¯ä¾èµ–: {' -> '.join(cycle)} -> {cycle[0]}"
                    })
        
        # æ£€æŸ¥ä¾èµ–è¿‡å¤šçš„æ¨¡å—ï¼ˆå¯èƒ½éœ€è¦æ‹†åˆ†ï¼‰
        for module_name, data in dependency_manager.graph.items():
            if len(data.get("depends_on", [])) > 5:  # ä¾èµ–è¿‡å¤šå¯èƒ½éœ€è¦æ‹†åˆ†
                split_suggestions.append({
                    "module": module_name,
                    "reason": f"ä¾èµ–è¿‡å¤š ({len(data['depends_on'])} ä¸ªä¾èµ–)"
                })
            if len(data.get("depended_by", [])) > 5:  # è¢«è¿‡å¤šæ¨¡å—ä¾èµ–å¯èƒ½éœ€è¦æ‹†åˆ†
                split_suggestions.append({
                    "module": module_name,
                    "reason": f"è¢«è¿‡å¤šæ¨¡å—ä¾èµ– ({len(data['depended_by'])} ä¸ªæ¨¡å—)"
                })
        
        # åˆ†æè´£ä»»è¿‡å¤šçš„æ¨¡å—
        for summary in summaries:
            name = summary.get("module_name", "")
            resps = summary.get("responsibilities", [])
            if isinstance(resps, list) and len(resps) > 8:  # è´£ä»»è¿‡å¤šå¯èƒ½éœ€è¦æ‹†åˆ†
                split_suggestions.append({
                    "module": name,
                    "reason": f"è´£ä»»è¿‡å¤š ({len(resps)} ä¸ªè´£ä»»)"
                })
    except Exception as e:
        print(f"âš ï¸ åˆ†ææ¨¡å—è¾¹ç•Œæ—¶å‡ºé”™: {e}")
    
    return {
        "merge_suggestions": merge_suggestions,
        "split_suggestions": split_suggestions
    }

async def run_validator(modules_to_check=None):
    """éªŒè¯æ¶æ„
    
    Args:
        modules_to_check: å¯é€‰ï¼ŒæŒ‡å®šè¦æ£€æŸ¥çš„æ¨¡å—åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ£€æŸ¥æ‰€æœ‰æ¨¡å—
    """
    input_path = Path("data/input")
    module_path = Path("data/output/modules")
    summary_index_path = Path("data/output/summary_index.json")
    output_json_path = Path("data/validator_report.json")

    requirement_docs = [f.read_text() for f in input_path.glob("*.md")]
    requirement_text = "\n\n".join(requirement_docs)

    # åŠ è½½æ¨¡å—æ‘˜è¦
    summaries = []
    for path in module_path.glob("*/full_summary.json"):
        try:
            # å¦‚æœæŒ‡å®šäº†è¦æ£€æŸ¥çš„æ¨¡å—ï¼ŒåªåŠ è½½è¿™äº›æ¨¡å—
            if modules_to_check:
                module_name = path.parent.name
                if module_name not in modules_to_check:
                    continue
            summaries.append(json.loads(path.read_text()))
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è§£æ {path}: {e}")

    # åŠ è½½å’Œæ›´æ–°ç´¢å¼•
    summary_index = {}
    if summary_index_path.exists():
        try:
            summary_index = json.loads(summary_index_path.read_text())
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½ç´¢å¼•: {e}")
    
    # æ›´æ–°ç´¢å¼•
    for summary in summaries:
        name = summary.get("module_name")
        if name:
            summary_index[name] = {
                "target_path": summary.get("target_path", ""),
                "depends_on": summary.get("depends_on", [])
            }
    
    # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
    summary_index_path.parent.mkdir(parents=True, exist_ok=True)
    summary_index_path.write_text(json.dumps(summary_index, indent=2))
    
    # åŠ è½½ä¾èµ–å›¾
    dependency_manager = DependencyManager()
    if not Path("data/output/dependency_graph.json").exists():
        dependency_manager.build_from_modules(module_path)
    
    # åˆ†ææ¨¡å—è¾¹ç•Œ
    boundary_analysis = analyze_module_boundaries(summaries, dependency_manager)
    print(f"ğŸ” è¾¹ç•Œåˆ†æå®Œæˆ:")
    print(f"  - åˆå¹¶å»ºè®®: {len(boundary_analysis['merge_suggestions'])}")
    print(f"  - æ‹†åˆ†å»ºè®®: {len(boundary_analysis['split_suggestions'])}")

    # æ¸…ç†ä¹‹å‰å¯èƒ½å­˜åœ¨çš„ç»“æœ
    if hasattr(custom_merge_sections, 'all_results'):
        delattr(custom_merge_sections, 'all_results')
    
    # AIéªŒè¯éƒ¨åˆ†çš„ä»£ç 
    if not modules_to_check and summaries:
        # åŠ è½½ä¹‹å‰çš„AIç»“æœï¼Œå¦‚æœå­˜åœ¨
        if output_json_path.exists():
            try:
                previous_result = json.loads(output_json_path.read_text())
                ai_result = previous_result.get("ai_review", {})
            except:
                pass
        
        # å‡†å¤‡LLMéªŒè¯çš„è¾“å…¥
        full_text = requirement_text + "\n\nSummaries:\n" + json.dumps(summaries, indent=2)
        
        try:
            tokenizer = tiktoken.encoding_for_model("gpt-4o")
            token_count = len(tokenizer.encode(full_text))
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆå§‹åŒ–tiktokenï¼Œä½¿ç”¨è¿‘ä¼¼è®¡ç®—: {str(e)}")
            # ä½¿ç”¨ç®€å•çš„å­—ç¬¦è®¡æ•°ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼ˆå‡è®¾å¹³å‡æ¯4ä¸ªå­—ç¬¦çº¦ç­‰äº1ä¸ªtokenï¼‰
            token_count = len(full_text) // 4
        
        print(f"ğŸ§  é€šè¿‡LLMéªŒè¯æ¶æ„å’Œæ‘˜è¦...")
        print(f"ğŸ“Š æ€»è¾“å…¥å¤§å°: {token_count} tokens")
        
        # é™åˆ¶è¾“å…¥å¤§å°ï¼Œé¿å…è¿‡å¤§çš„æ–‡æœ¬
        if token_count > 100000:  # è¶…è¿‡10ä¸‡tokensï¼Œå¯èƒ½å¤ªå¤§äº†
            print(f"âš ï¸ è¾“å…¥æ–‡æœ¬è¿‡å¤§ï¼Œè¿›è¡Œæˆªæ–­...")
            # åªä¿ç•™æ‘˜è¦çš„ç®€è¦ä¿¡æ¯
            brief_summaries = []
            for s in summaries:
                brief_summary = {
                    "module_name": s.get("module_name", ""),
                    "responsibilities": s.get("responsibilities", [])[:3],  # åªä¿ç•™å‰3ä¸ªèŒè´£
                    "depends_on": s.get("depends_on", []),
                    "layer_type": s.get("layer_type", "")
                }
                brief_summaries.append(brief_summary)
            
            full_text = requirement_text + "\n\nSummaries (abbreviated):\n" + json.dumps(brief_summaries, indent=2)
            print(f"ğŸ“Š æˆªæ–­åå¤§å°: {len(tokenizer.encode(full_text))} tokens")
        
        # å°è¯•å¤šæ¬¡è§£æï¼Œæé«˜æˆåŠŸç‡
        for attempt in range(3):  # æœ€å¤šå°è¯•3æ¬¡
            try:
                # ä½¿ç”¨run_promptè¿›è¡Œå¤„ç†ï¼Œä½†æä¾›è‡ªå®šä¹‰åˆå¹¶å‡½æ•°
                print(f"ğŸ“¦ å¯åŠ¨ç¬¬ {attempt+1} æ¬¡éªŒè¯å°è¯•...")
                
                # æ˜ç¡®å‘ŠçŸ¥LLMæˆ‘ä»¬ä¼šåˆ†æ®µå‘é€
                def get_enhanced_prompt(i, total):
                    base_prompt = get_validator_prompt(i, total, boundary_analysis)
                    
                    # å¯¹ç¬¬ä¸€éƒ¨åˆ†æ·»åŠ ç‰¹æ®ŠæŒ‡ä»¤
                    if i == 0 or i == 1:
                        return base_prompt + "\n\né‡è¦è¯´æ˜ï¼šæˆ‘å°†åˆ†å¤šä¸ªéƒ¨åˆ†å‘é€æ–‡æ¡£ï¼Œè¯·åœ¨æ”¶åˆ°å…¨éƒ¨å†…å®¹åå†è¿›è¡Œåˆ†æå›å¤ã€‚"
                    
                    # å¯¹æœ€åä¸€éƒ¨åˆ†æ·»åŠ ç‰¹æ®ŠæŒ‡ä»¤
                    if i == total:
                        return base_prompt + "\n\nè¿™æ˜¯æœ€åä¸€éƒ¨åˆ†ï¼Œè¯·åŸºäºå…¨éƒ¨æ¥æ”¶åˆ°çš„å†…å®¹æä¾›å®Œæ•´åˆ†æã€‚å¿…é¡»ä½¿ç”¨JSONæ ¼å¼è¿”å›ç»“æœã€‚"
                    
                    # å¯¹ä¸­é—´éƒ¨åˆ†
                    return "ç»§ç»­æ¥æ”¶ç¬¬ " + str(i) + "/" + str(total) + " éƒ¨åˆ†å†…å®¹ã€‚è¯·ç­‰å¾…å®Œæ•´æ¥æ”¶æ‰€æœ‰éƒ¨åˆ†åå†å›å¤ã€‚"
                
                print("ğŸ“¦ å¼€å§‹éªŒè¯å¤„ç†...")
                # ä½¿ç”¨è¾ƒå¤§çš„max_input_tokensæ¥å‡å°‘åˆ†å—æ•°é‡
                ai_result = await run_prompt(
                    chat=chat,
                    user_prompt=full_text,
                    model="gpt-4o",
                    tokenizer=tokenizer,
                    max_input_tokens=15000,  # å¢åŠ å•å—å¤§å°ä»¥å‡å°‘åˆ†å—æ•°
                    parse_response=parse_json_response,
                    merge_result=custom_merge_sections,  # ä½¿ç”¨è‡ªå®šä¹‰çš„éé€’å½’åˆå¹¶å‡½æ•°
                    get_system_prompt=get_enhanced_prompt,  # ä½¿ç”¨å¢å¼ºçš„ç³»ç»Ÿæç¤º
                    use_pipeline=False  # å…³é—­æµæ°´çº¿æ¨¡å¼ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
                )
                
                # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
                if ai_result and isinstance(ai_result, dict) and "functional_coverage" in ai_result:
                    print("âœ… æˆåŠŸè·å–AIéªŒè¯ç»“æœ")
                    break
                else:
                    print(f"âš ï¸ å°è¯• {attempt+1}/3: AIç»“æœæ— æ•ˆï¼Œé‡è¯•...")
                    time.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
            except Exception as e:
                print(f"âš ï¸ å°è¯• {attempt+1}/3: AIéªŒè¯å¤±è´¥ - {str(e)[:200]}")
                time.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
        
        if not ai_result or not isinstance(ai_result, dict) or "functional_coverage" not in ai_result:
            print("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„AIéªŒè¯ç»“æœï¼Œä½¿ç”¨é»˜è®¤ç©ºç»“æ„")
            ai_result = {
                "functional_coverage": {"conclusion": "â“", "explanation": "éªŒè¯å¤±è´¥"},
                "missing_or_redundant_modules": {"missing": [], "redundant": []},
                "overlapping_responsibilities": [],
                "undefined_dependencies": [],
                "suggestions": ["ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•å®Œæˆå®Œæ•´éªŒè¯"]
            }

        # åœ¨run_promptä¹‹åï¼Œå¤„ç†æ”¶é›†åˆ°çš„æ‰€æœ‰ç»“æœ
        if hasattr(custom_merge_sections, 'all_results') and custom_merge_sections.all_results:
            print(f"ğŸ“ åˆå¹¶æ‰€æœ‰æ”¶é›†åˆ°çš„ç»“æœ ({len(custom_merge_sections.all_results)} ä¸ªå—)...")
            
            # å°†æ‰€æœ‰ç»“æœå†™å…¥ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿æŸ¥çœ‹
            temp_file = Path("data/temp_collected_results.json")
            temp_file.parent.mkdir(parents=True, exist_ok=True)
            temp_file.write_text(json.dumps(custom_merge_sections.all_results, indent=2))
            print(f"âœï¸ åŸå§‹ç»“æœå·²å†™å…¥: {temp_file}")
            
            # è¿™é‡Œå…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºåŸºç¡€ç»“æ„
            ai_result = custom_merge_sections.all_results[0] if custom_merge_sections.all_results else {}
            
            # æ¸…ç†æ”¶é›†åˆ°çš„ç»“æœ
            delattr(custom_merge_sections, 'all_results')

    # ç»“æ„éªŒè¯
    local_structure_issues = {}
    for path in module_path.glob("*/full_summary.json"):
        try:
            # å¦‚æœæŒ‡å®šäº†è¦æ£€æŸ¥çš„æ¨¡å—ï¼Œåªæ£€æŸ¥è¿™äº›æ¨¡å—
            module_name = path.parent.name
            if modules_to_check and module_name not in modules_to_check:
                continue
                
            data = json.loads(path.read_text())
            check_module_structure(data, summary_index, local_structure_issues)
        except Exception as e:
            module_name = path.parent.name
            local_structure_issues[module_name] = [f"failed to parse: {e}"]

    # å¦‚æœä¿ç•™ä¹‹å‰çš„ç»“æ„é—®é¢˜
    if modules_to_check and output_json_path.exists():
        try:
            previous_report = json.loads(output_json_path.read_text())
            previous_issues = previous_report.get("structure_scan", {})
            
            # ä¿ç•™æœªä¿®æ”¹æ¨¡å—çš„é—®é¢˜
            for module, issues in previous_issues.items():
                if module not in modules_to_check and module not in local_structure_issues:
                    local_structure_issues[module] = issues
        except:
            pass

    # ç”ŸæˆæŠ¥å‘Š
    report = {
        "ai_review": ai_result,
        "structure_scan": local_structure_issues,
        "boundary_analysis": boundary_analysis
    }
    
    # ä¿å­˜æŠ¥å‘Š
    output_json_path.parent.mkdir(parents=True, exist_ok=True)
    output_json_path.write_text(json.dumps(report, indent=2))
    
    print(f"âœ… ç»“æ„åŒ–æŠ¥å‘Šå·²å†™å…¥ {output_json_path}")
    
    # è¿”å›é—®é¢˜è®¡æ•°
    issue_count = sum(len(issues) for _, issues in local_structure_issues.items())
    issue_count += len(ai_result.get("overlapping_responsibilities", []))
    issue_count += len(ai_result.get("undefined_dependencies", []))
    issue_count += len(ai_result.get("missing_or_redundant_modules", {}).get("missing", []))
    issue_count += len(ai_result.get("missing_or_redundant_modules", {}).get("redundant", []))
    
    return {
        "total_issues": issue_count,
        "structure_issues": sum(len(issues) for _, issues in local_structure_issues.items()),
        "overlapping": len(ai_result.get("overlapping_responsibilities", [])),
        "undefined": len(ai_result.get("undefined_dependencies", [])),
        "missing": len(ai_result.get("missing_or_redundant_modules", {}).get("missing", [])),
        "redundant": len(ai_result.get("missing_or_redundant_modules", {}).get("redundant", []))
    }

if __name__ == "__main__":
    result = asyncio.run(run_validator())
    print(f"ğŸ” éªŒè¯ç»“æœ: å‘ç° {result['total_issues']} ä¸ªé—®é¢˜")
    print(f"  - ç»“æ„é—®é¢˜: {result['structure_issues']}")
    print(f"  - é‡å è´£ä»»: {result['overlapping']}")
    print(f"  - æœªå®šä¹‰ä¾èµ–: {result['undefined']}")
    print(f"  - ç¼ºå¤±æ¨¡å—: {result['missing']}")
    print(f"  - å†—ä½™æ¨¡å—: {result['redundant']}")
