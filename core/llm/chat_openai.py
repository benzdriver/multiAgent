"""
Interface to OpenAI chat models
"""

import os
import asyncio
from openai import AsyncOpenAI
from typing import List, Dict, Optional, Union, Any

# Check if API key is present
api_key = os.environ.get("OPENAI_API_KEY_OPENAI_API_KEY")
if not api_key:
    print("âš ï¸ OPENAI_API_KEY_OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼ŒOpenAI APIè°ƒç”¨å°†ä¼šå¤±è´¥")
    print("è¯·è®¾ç½®OPENAI_API_KEY_OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼Œæˆ–ä½¿ç”¨æ¨¡æ‹Ÿå“åº”æ¨¡å¼")

client = None

def get_client():
    global client
    if client is None:
        if os.environ.get("USE_MOCK_LLM") == "True":
            mock_api_key = "sk-mock-key-for-testing"
            client = AsyncOpenAI(api_key=mock_api_key)
        else:
            client = AsyncOpenAI(api_key=api_key)
    return client

# Retry parameters
MAX_RETRIES = 3
RETRY_DELAY = 10  # seconds

async def chat(
    system_message: Optional[str] = None,
    user_message: Optional[str] = None,
    model: str = "gpt-4o",
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
    stop: Optional[List[str]] = None,
    messages: Optional[List[Dict[str, str]]] = None
) -> Any:
    """
    Interact with OpenAI chat models
    
    æ”¯æŒä¸‰ç§è°ƒç”¨æ–¹å¼ï¼š
    1. messages: ç›´æ¥ä¼ å®Œæ•´å†å²
    2. system_message + user_message: ç»„è£… system+user
    3. user_message: å•è½® user æ¶ˆæ¯
    
    Args:
        system_message: System prompt
        user_message: User message
        model: Model name
        temperature: Temperature parameter
        max_tokens: Maximum tokens to generate
        stop: List of stop tokens
        messages: Complete message history list
    Returns:
        Model response content
    """
    # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if not api_key:
        error_msg = "OpenAI APIå¯†é’¥æœªè®¾ç½®ã€‚è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡ã€‚"
        print(f"âŒ {error_msg}")
        return {
            "error": error_msg,
            "status": "api_key_missing"
        }
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    if messages:
        message_list = messages
    elif system_message and user_message:
        message_list = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
    elif user_message:
        message_list = [
            {"role": "user", "content": user_message}
        ]
    else:
        error_msg = "Must provide one of these parameter combinations: (messages), (system_message, user_message), or (user_message)"
        print(f"âŒ {error_msg}")
        return {
            "error": error_msg,
            "status": "invalid_parameters"
        }
    # ä½¿ç”¨è¿­ä»£è€Œä¸æ˜¯é€’å½’çš„æ–¹å¼å¤„ç†é‡è¯•
    last_error = None
    for attempt in range(MAX_RETRIES):
        try:
            print(f"ğŸ›°ï¸ å‘é€OpenAI APIè¯·æ±‚ (å°è¯• {attempt+1}/{MAX_RETRIES})")
            current_client = get_client()
            response = await current_client.chat.completions.create(
                model=model,
                messages=message_list,
                temperature=temperature,
                max_tokens=max_tokens,
                stop=stop
            )
            return response.choices[0].message.content
        except Exception as e:
            last_error = e
            if attempt < MAX_RETRIES - 1:
                print(f"âš ï¸ APIè¯·æ±‚å¤±è´¥: {str(e)[:200]}")
                print(f"â³ {RETRY_DELAY}ç§’åé‡è¯•...")
                await asyncio.sleep(RETRY_DELAY)
            else:
                print(f"âŒ OpenAI APIè¯·æ±‚åœ¨ {MAX_RETRIES} æ¬¡å°è¯•åå¤±è´¥")
                break
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
    if last_error:
        error_msg = f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(last_error)}"
        print(f"âŒ {error_msg}")
        return {
            "error": error_msg,
            "status": "api_call_failed",
            "exception": str(last_error)
        }
    return {
        "error": "æœªçŸ¥é”™è¯¯",
        "status": "unknown_error"
    }
