from pathlib import Path
import json
from typing import Dict, List, Any, Callable, Awaitable
from llm.llm_executor import run_prompt
from llm.prompt_cleaner import clean_code_output


class ArchitectureGenerator:
    """æ¶æ„ç”Ÿæˆå™¨ï¼Œè´Ÿè´£ç”Ÿæˆæ¶æ„æ–‡æ¡£"""

    def __init__(self, logger=None):
        self.output_dir = Path("data/output/architecture")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger
    
    async def analyze_architecture_needs(self, requirement_analysis: Dict, llm_call: Callable) -> Dict:
        """æ ¹æ®éœ€æ±‚åˆ†æç»“æœï¼Œåˆ†ææ¶æ„éœ€æ±‚
        
        Args:
            requirement_analysis: éœ€æ±‚åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
            
        Returns:
            æ¶æ„éœ€æ±‚åˆ†æç»“æœ
        """
        if self.logger:
            self.logger.log("\nğŸ” æ­£åœ¨åˆ†ææ¶æ„éœ€æ±‚...", role="system")
        else:
            print("\nğŸ” æ­£åœ¨åˆ†ææ¶æ„éœ€æ±‚...")
        
        prompt = f"""
        åŸºäºä»¥ä¸‹éœ€æ±‚åˆ†æç»“æœï¼Œç¡®å®šç³»ç»Ÿæ¶æ„éœ€æ±‚ï¼š
        
        {json.dumps(requirement_analysis, ensure_ascii=False, indent=2)}
        
        è¯·åˆ†æå¹¶ç¡®å®šé€‚åˆè¯¥ç³»ç»Ÿçš„æ¶æ„æ¨¡å¼ã€å±‚æ¬¡ç»“æ„å’ŒæŠ€æœ¯é€‰å‹ã€‚è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š
        
        1. æ¨èçš„æ¶æ„æ¨¡å¼ï¼ˆå¦‚å¾®æœåŠ¡ã€å•ä½“ã€äº‹ä»¶é©±åŠ¨ç­‰ï¼‰åŠç†ç”±
        2. ç³»ç»Ÿåˆ†å±‚ï¼ˆå¦‚å‰ç«¯ã€åç«¯ã€æ•°æ®å±‚ç­‰ï¼‰åŠæ¯å±‚çš„èŒè´£
        3. æ ¸å¿ƒç»„ä»¶åŠå…¶äº¤äº’æ–¹å¼
        4. å…³é”®æ¥å£å®šä¹‰
        5. æŠ€æœ¯æ ˆé€‰æ‹©åŠç†ç”±
        6. éƒ¨ç½²æ¶æ„å»ºè®®
        7. å¯æ‰©å±•æ€§å’Œæ€§èƒ½è€ƒè™‘
        
        ä»¥JSONæ ¼å¼è¿”å›ï¼Œç»“æ„å¦‚ä¸‹ï¼š
        
        {{
            "architecture_pattern": {{
                "name": "æ¶æ„æ¨¡å¼åç§°",
                "rationale": "é€‰æ‹©ç†ç”±",
                "advantages": ["ä¼˜åŠ¿1", "ä¼˜åŠ¿2"],
                "challenges": ["æŒ‘æˆ˜1", "æŒ‘æˆ˜2"]
            }},
            "layers": [
                {{
                    "name": "å±‚åç§°",
                    "responsibilities": ["èŒè´£1", "èŒè´£2"],
                    "components": ["ç»„ä»¶1", "ç»„ä»¶2"]
                }}
            ],
            "core_components": [
                {{
                    "name": "ç»„ä»¶åç§°",
                    "description": "ç»„ä»¶æè¿°",
                    "responsibilities": ["èŒè´£1", "èŒè´£2"],
                    "interfaces": ["æ¥å£1", "æ¥å£2"]
                }}
            ],
            "key_interfaces": [
                {{
                    "name": "æ¥å£åç§°",
                    "description": "æ¥å£æè¿°",
                    "operations": ["æ“ä½œ1", "æ“ä½œ2"],
                    "data_format": "æ•°æ®æ ¼å¼"
                }}
            ],
            "technology_stack": [
                {{
                    "category": "ç±»åˆ«",
                    "technology": "æŠ€æœ¯åç§°",
                    "rationale": "é€‰æ‹©ç†ç”±"
                }}
            ],
            "deployment_architecture": {{
                "model": "éƒ¨ç½²æ¨¡å‹",
                "environments": ["ç¯å¢ƒ1", "ç¯å¢ƒ2"],
                "infrastructure": "åŸºç¡€è®¾æ–½æè¿°"
            }},
            "scalability_considerations": [
                "è€ƒè™‘ç‚¹1", "è€ƒè™‘ç‚¹2"
            ]
        }}
        
        ç¡®ä¿æ‚¨çš„å»ºè®®ä¸éœ€æ±‚åˆ†æç»“æœä¸€è‡´ï¼Œå¹¶è€ƒè™‘æ‰€æœ‰åŠŸèƒ½å’ŒéåŠŸèƒ½éœ€æ±‚ã€‚
        
        **è¯·ä¸¥æ ¼åªè¿”å›JSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€è¯´æ˜ã€æ³¨é‡Šæˆ–å¤šä½™å†…å®¹ã€‚**
        """
        
        # è°ƒç”¨LLMè·å–åˆ†æç»“æœ
        if self.logger:
            self.logger.log(f"LLMè¾“å…¥ï¼š{prompt[:200]}...", role="llm_prompt")
        result = await llm_call(prompt, parse_response=clean_code_output)
        if self.logger:
            self.logger.log(f"LLMå“åº”ï¼š{str(result)[:200]}...", role="llm_response")
        
        # å¦‚æœç»“æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æJSON
        if isinstance(result, str):
            try:
                result = json.loads(result)
            except Exception as e:
                if self.logger:
                    self.logger.log(f"è­¦å‘Šï¼šæ¶æ„éœ€æ±‚åˆ†æç»“æœè§£æå¤±è´¥: {e}", role="error")
                    self.logger.log("LLMåŸå§‹è¿”å›å†…å®¹å¦‚ä¸‹ï¼š\n" + result, role="llm_response")
                else:
                    print(f"è­¦å‘Šï¼šæ¶æ„éœ€æ±‚åˆ†æç»“æœè§£æå¤±è´¥: {e}")
                    print("LLMåŸå§‹è¿”å›å†…å®¹å¦‚ä¸‹ï¼š\n" + result)
                # ç›´æ¥è¿”å›åŸå§‹å†…å®¹ï¼Œæ–¹ä¾¿ç”¨æˆ·äººå·¥åˆ¤æ–­
                return result
        
        return result
    
    async def generate_architecture_documents(self, requirement_analysis: Dict, architecture_analysis: Dict, llm_call: Callable):
        """ç”Ÿæˆæ¶æ„æ–‡æ¡£
        
        Args:
            requirement_analysis: éœ€æ±‚åˆ†æç»“æœ
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
        """
        if self.logger:
            self.logger.log("\nğŸ“ ç”Ÿæˆæ¶æ„æ–‡æ¡£...", role="system")
        else:
            print("\nğŸ“ ç”Ÿæˆæ¶æ„æ–‡æ¡£...")
        await self._generate_architecture_overview(requirement_analysis, architecture_analysis, llm_call)
        await self._generate_detailed_design(requirement_analysis, architecture_analysis, llm_call)
        await self._generate_interface_documentation(architecture_analysis, llm_call)
        await self._generate_deployment_documentation(architecture_analysis, llm_call)
        if self.logger:
            self.logger.log(f"âœ… æ¶æ„æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼å·²ä¿å­˜åˆ°ï¼š{self.output_dir}", role="system")
        else:
            print(f"âœ… æ¶æ„æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼å·²ä¿å­˜åˆ°ï¼š{self.output_dir}")
    
    async def _generate_architecture_overview(self, requirement_analysis: Dict, architecture_analysis: Dict, llm_call: Callable):
        """ç”Ÿæˆæ¶æ„æ¦‚è¿°æ–‡æ¡£
        
        Args:
            requirement_analysis: éœ€æ±‚åˆ†æç»“æœ
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
        """
        if self.logger:
            self.logger.log("- ç”Ÿæˆæ¶æ„æ¦‚è¿°æ–‡æ¡£...", role="system")
        else:
            print("- ç”Ÿæˆæ¶æ„æ¦‚è¿°æ–‡æ¡£...")
        
        prompt = f"""
        åŸºäºä»¥ä¸‹éœ€æ±‚åˆ†æå’Œæ¶æ„åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªæ¶æ„æ¦‚è¿°æ–‡æ¡£ï¼š
        
        éœ€æ±‚åˆ†æï¼š
        {json.dumps(requirement_analysis, ensure_ascii=False, indent=2)}
        
        æ¶æ„åˆ†æï¼š
        {json.dumps(architecture_analysis, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªMarkdownæ ¼å¼çš„æ¶æ„æ¦‚è¿°æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
        
        1. å¼•è¨€
           - æ–‡æ¡£ç›®çš„
           - ç³»ç»ŸèƒŒæ™¯
           - æ¶æ„ç›®æ ‡
           
        2. æ¶æ„å†³ç­–
           - æ‰€é€‰æ¶æ„æ¨¡å¼åŠç†ç”±
           - å…³é”®è®¾è®¡å†³ç­–
           - å¤‡é€‰æ–¹æ¡ˆåˆ†æ
           
        3. ç³»ç»Ÿæ¦‚è¿°
           - é«˜å±‚æ¶æ„å›¾ï¼ˆç”¨æ–‡æœ¬æè¿°ï¼‰
           - ä¸»è¦ç»„ä»¶
           - ç³»ç»Ÿè¾¹ç•Œ
           - å¤–éƒ¨ä¾èµ–
           
        4. æ¶æ„ç‰¹æ€§
           - å¯æ‰©å±•æ€§
           - æ€§èƒ½
           - å®‰å…¨æ€§
           - å¯ç»´æŠ¤æ€§
           - å®¹é”™æ€§
           
        5. æŠ€æœ¯æ ˆ
           - é€‰å‹åŠç†ç”±
           - ç‰ˆæœ¬ä¿¡æ¯
           
        ç¡®ä¿æ–‡æ¡£æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶ä¸éœ€æ±‚å’Œæ¶æ„åˆ†æä¿æŒä¸€è‡´ã€‚
        """
        
        overview_content = await llm_call(prompt)
        
        # ä¿å­˜æ¶æ„æ¦‚è¿°æ–‡æ¡£
        overview_file = self.output_dir / "01_architecture_overview.md"
        
        # å¦‚æœç»“æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(overview_content, dict):
            overview_content = json.dumps(overview_content, ensure_ascii=False, indent=2)
            
        with open(overview_file, 'w', encoding='utf-8') as f:
            f.write(overview_content)
        
        if self.logger:
            self.logger.log(f"  âœ“ æ¶æ„æ¦‚è¿°æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{overview_file}", role="system")
        else:
            print(f"  âœ“ æ¶æ„æ¦‚è¿°æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{overview_file}")
    
    async def _generate_detailed_design(self, requirement_analysis: Dict, architecture_analysis: Dict, llm_call: Callable):
        """ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£
        
        Args:
            requirement_analysis: éœ€æ±‚åˆ†æç»“æœ
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
        """
        if self.logger:
            self.logger.log("- ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£...", role="system")
        else:
            print("- ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£...")
        
        prompt = f"""
        åŸºäºä»¥ä¸‹éœ€æ±‚åˆ†æå’Œæ¶æ„åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼š
        
        éœ€æ±‚åˆ†æï¼š
        {json.dumps(requirement_analysis, ensure_ascii=False, indent=2)}
        
        æ¶æ„åˆ†æï¼š
        {json.dumps(architecture_analysis, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªMarkdownæ ¼å¼çš„è¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
        
        1. ç³»ç»Ÿåˆ†å±‚
           - å„å±‚èŒè´£
           - å±‚é—´ä¾èµ–
           - å±‚å†…ç»„ä»¶
           
        2. æ ¸å¿ƒç»„ä»¶è¯¦ç»†è®¾è®¡
           - æ¯ä¸ªç»„ä»¶çš„è¯¦ç»†æè¿°
           - ç»„ä»¶èŒè´£
           - ç»„ä»¶ä¾èµ–
           - å…³é”®ç®—æ³•å’Œæ•°æ®ç»“æ„
           - çŠ¶æ€ç®¡ç†
           
        3. æ•°æ®æ¨¡å‹
           - ä¸»è¦å®ä½“
           - å®ä½“å…³ç³»
           - æ•°æ®æµ
           
        4. å¼‚å¸¸å¤„ç†
           - é”™è¯¯å¤„ç†ç­–ç•¥
           - æ—¥å¿—å’Œç›‘æ§
           
        5. å®‰å…¨è®¾è®¡
           - è®¤è¯ä¸æˆæƒ
           - æ•°æ®å®‰å…¨
           - é€šä¿¡å®‰å…¨
           
        ç¡®ä¿æ–‡æ¡£è¯¦ç»†ã€å‡†ç¡®ï¼Œå¹¶ä¸éœ€æ±‚å’Œæ¶æ„åˆ†æä¿æŒä¸€è‡´ã€‚ä¸ºæ¯ä¸ªç»„ä»¶æä¾›è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œä½¿å¼€å‘å›¢é˜Ÿèƒ½å¤ŸåŸºäºæ­¤æ–‡æ¡£è¿›è¡Œå®ç°ã€‚
        """
        
        design_content = await llm_call(prompt)
        
        # ä¿å­˜è¯¦ç»†è®¾è®¡æ–‡æ¡£
        design_file = self.output_dir / "02_detailed_design.md"
        
        # å¦‚æœç»“æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(design_content, dict):
            design_content = json.dumps(design_content, ensure_ascii=False, indent=2)
            
        with open(design_file, 'w', encoding='utf-8') as f:
            f.write(design_content)
        
        if self.logger:
            self.logger.log(f"  âœ“ è¯¦ç»†è®¾è®¡æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{design_file}", role="system")
        else:
            print(f"  âœ“ è¯¦ç»†è®¾è®¡æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{design_file}")
    
    async def _generate_interface_documentation(self, architecture_analysis: Dict, llm_call: Callable):
        """ç”Ÿæˆæ¥å£æ–‡æ¡£
        
        Args:
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
        """
        if self.logger:
            self.logger.log("- ç”Ÿæˆæ¥å£æ–‡æ¡£...", role="system")
        else:
            print("- ç”Ÿæˆæ¥å£æ–‡æ¡£...")
        
        prompt = f"""
        åŸºäºä»¥ä¸‹æ¶æ„åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªæ¥å£æ–‡æ¡£ï¼š
        
        {json.dumps(architecture_analysis, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªMarkdownæ ¼å¼çš„æ¥å£æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
        
        1. æ¥å£æ¦‚è¿°
           - æ¥å£è®¾è®¡åŸåˆ™
           - æ¥å£åˆ†ç±»
           
        2. APIå®šä¹‰
           - å¯¹äºæ¯ä¸ªAPIæ¥å£ï¼š
             - æ¥å£åç§°
             - æ¥å£URL/è·¯å¾„
             - è¯·æ±‚æ–¹æ³•
             - è¯·æ±‚å‚æ•°
             - å“åº”æ ¼å¼
             - çŠ¶æ€ç 
             - ç¤ºä¾‹è¯·æ±‚å’Œå“åº”
             - é”™è¯¯å¤„ç†
             
        3. å†…éƒ¨æ¥å£
           - ç»„ä»¶é—´æ¥å£
           - æ¨¡å—é—´é€šä¿¡
           - äº‹ä»¶å®šä¹‰
           
        4. å¤–éƒ¨æ¥å£
           - ä¸ç¬¬ä¸‰æ–¹ç³»ç»Ÿçš„é›†æˆæ¥å£
           - æ•°æ®äº¤æ¢æ ¼å¼
           
        5. æ¥å£ç‰ˆæœ¬æ§åˆ¶
           - ç‰ˆæœ¬ç®¡ç†ç­–ç•¥
           - å‘åå…¼å®¹æ€§è€ƒè™‘
           
        ç¡®ä¿æ–‡æ¡£è¯¦ç»†ã€å‡†ç¡®ï¼Œä¸ºæ¯ä¸ªæ¥å£æä¾›è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œä½¿å¼€å‘å›¢é˜Ÿèƒ½å¤ŸåŸºäºæ­¤æ–‡æ¡£è¿›è¡Œå®ç°å’Œé›†æˆã€‚
        """
        
        interface_content = await llm_call(prompt)
        
        # ä¿å­˜æ¥å£æ–‡æ¡£
        interface_file = self.output_dir / "03_interfaces.md"
        
        # å¦‚æœç»“æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(interface_content, dict):
            interface_content = json.dumps(interface_content, ensure_ascii=False, indent=2)
            
        with open(interface_file, 'w', encoding='utf-8') as f:
            f.write(interface_content)
        
        if self.logger:
            self.logger.log(f"  âœ“ æ¥å£æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{interface_file}", role="system")
        else:
            print(f"  âœ“ æ¥å£æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{interface_file}")
    
    async def _generate_deployment_documentation(self, architecture_analysis: Dict, llm_call: Callable):
        """ç”Ÿæˆéƒ¨ç½²æ–‡æ¡£
        
        Args:
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
            llm_call: LLMè°ƒç”¨å‡½æ•°
        """
        if self.logger:
            self.logger.log("- ç”Ÿæˆéƒ¨ç½²æ–‡æ¡£...", role="system")
        else:
            print("- ç”Ÿæˆéƒ¨ç½²æ–‡æ¡£...")
        
        prompt = f"""
        åŸºäºä»¥ä¸‹æ¶æ„åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä¸ªéƒ¨ç½²æ–‡æ¡£ï¼š
        
        {json.dumps(architecture_analysis, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªMarkdownæ ¼å¼çš„éƒ¨ç½²æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
        
        1. éƒ¨ç½²æ¶æ„
           - éƒ¨ç½²æ‹“æ‰‘å›¾ï¼ˆç”¨æ–‡æœ¬æè¿°ï¼‰
           - ç¯å¢ƒå®šä¹‰ï¼ˆå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ï¼‰
           - ç»„ä»¶éƒ¨ç½²åˆ†å¸ƒ
           
        2. åŸºç¡€è®¾æ–½éœ€æ±‚
           - æœåŠ¡å™¨è§„æ ¼
           - ç½‘ç»œè¦æ±‚
           - å­˜å‚¨éœ€æ±‚
           - ä¸­é—´ä»¶å’Œç¬¬ä¸‰æ–¹æœåŠ¡
           
        3. éƒ¨ç½²æµç¨‹
           - æ„å»ºè¿‡ç¨‹
           - éƒ¨ç½²æ­¥éª¤
           - é…ç½®ç®¡ç†
           - æŒç»­é›†æˆ/æŒç»­éƒ¨ç½²ç­–ç•¥
           
        4. è¿ç»´è€ƒè™‘
           - ç›‘æ§ç­–ç•¥
           - å¤‡ä»½å’Œæ¢å¤
           - æ‰©å±•ç­–ç•¥
           - æ•…éšœè½¬ç§»
           
        5. æ€§èƒ½ä¼˜åŒ–
           - ç¼“å­˜ç­–ç•¥
           - è´Ÿè½½å‡è¡¡
           - æ•°æ®åº“ä¼˜åŒ–
           
        ç¡®ä¿æ–‡æ¡£è¯¦ç»†ã€å‡†ç¡®ï¼Œä¸ºéƒ¨ç½²å’Œè¿ç»´å›¢é˜Ÿæä¾›è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œä½¿ä»–ä»¬èƒ½å¤ŸåŸºäºæ­¤æ–‡æ¡£è¿›è¡Œç³»ç»Ÿéƒ¨ç½²å’Œç»´æŠ¤ã€‚
        """
        
        deployment_content = await llm_call(prompt)
        
        # ä¿å­˜éƒ¨ç½²æ–‡æ¡£
        deployment_file = self.output_dir / "04_deployment.md"
        
        # å¦‚æœç»“æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(deployment_content, dict):
            deployment_content = json.dumps(deployment_content, ensure_ascii=False, indent=2)
            
        with open(deployment_file, 'w', encoding='utf-8') as f:
            f.write(deployment_content)
        
        if self.logger:
            self.logger.log(f"  âœ“ éƒ¨ç½²æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{deployment_file}", role="system")
        else:
            print(f"  âœ“ éƒ¨ç½²æ–‡æ¡£å·²ä¿å­˜åˆ°ï¼š{deployment_file}")
    
    async def save_architecture_state(self, requirement_analysis: Dict, architecture_analysis: Dict):
        """ä¿å­˜æ¶æ„çŠ¶æ€
        
        Args:
            requirement_analysis: éœ€æ±‚åˆ†æç»“æœ
            architecture_analysis: æ¶æ„åˆ†æç»“æœ
        """
        if self.logger:
            self.logger.log("- ä¿å­˜æ¶æ„çŠ¶æ€...", role="system")
        else:
            print("- ä¿å­˜æ¶æ„çŠ¶æ€...")
        
        from datetime import datetime
        
        architecture_state = {
            "requirement_analysis": requirement_analysis,
            "architecture_analysis": architecture_analysis,
            "timestamp": datetime.now().isoformat()
        }
        
        # ä¿å­˜æ¶æ„çŠ¶æ€
        state_file = self.output_dir / "architecture_state.json"
        
        with open(state_file, 'w', encoding='utf-8') as f:
            json.dump(architecture_state, f, ensure_ascii=False, indent=2)
        
        if self.logger:
            self.logger.log(f"  âœ“ æ¶æ„çŠ¶æ€å·²ä¿å­˜åˆ°ï¼š{state_file}", role="system")
        else:
            print(f"  âœ“ æ¶æ„çŠ¶æ€å·²ä¿å­˜åˆ°ï¼š{state_file}") 