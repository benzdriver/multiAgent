from pathlib import Path
from typing import Dict, List, Optional
import asyncio
import json
from llm.llm_executor import run_prompt

class DocumentProcessor:
    """è´Ÿè´£è¯»å–å’Œåˆ†ææ–‡æ¡£"""
    
    def __init__(self, input_path: Path = None, logger=None):
        """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨"""
        self.input_path = input_path or Path("data/input")
        if not self.input_path.exists():
            self.input_path.mkdir(parents=True, exist_ok=True)
        self.logger = logger
    
    async def read_all_markdown_files(self) -> Dict[str, str]:
        """è¯»å–inputç›®å½•ä¸‹çš„æ‰€æœ‰markdownæ–‡ä»¶"""
        documents = {}
        
        if not self.input_path.exists():
            if self.logger:
                self.logger.log(f"åˆ›å»ºè¾“å…¥ç›®å½•ï¼š{self.input_path}", role="system")
            else:
                print(f"åˆ›å»ºè¾“å…¥ç›®å½•ï¼š{self.input_path}")
            self.input_path.mkdir(parents=True)
            return documents
            
        for file_path in self.input_path.glob("*.md"):
            try:
                content = file_path.read_text(encoding='utf-8')
                documents[file_path.name] = content
                if self.logger:
                    self.logger.log(f"âœ“ å·²è¯»å–: {file_path.name}", role="system")
                else:
                    print(f"âœ“ å·²è¯»å–: {file_path.name}")
            except Exception as e:
                if self.logger:
                    self.logger.log(f"âš ï¸ è¯»å–æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {str(e)}", role="error")
                else:
                    print(f"âš ï¸ è¯»å–æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {str(e)}")
                
        return documents
    
    async def analyze_all_documents(self, documents: Dict[str, str], llm_call) -> Dict:
        """åˆ†ææ‰€æœ‰æ–‡æ¡£å¹¶ç†è§£æ¶æ„"""
        print("\nğŸ” æ­£åœ¨åˆ†ææ‰€æœ‰æ–‡æ¡£...")
        
        # å°†æ‰€æœ‰æ–‡æ¡£å†…å®¹ç»„åˆæˆä¸€ä¸ªä¸Šä¸‹æ–‡
        combined_content = "\n\n=== æ–‡æ¡£åˆ†éš”ç¬¦ ===\n\n".join(
            f"æ–‡ä»¶ï¼š{filename}\n\n{content}" 
            for filename, content in documents.items()
        )
        
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹æ‰€æœ‰æ–‡æ¡£ï¼Œç†è§£ç³»ç»Ÿçš„æ•´ä½“æ¶æ„è®¾è®¡ï¼š

        {combined_content}

        è¯·æä¾›å®Œæ•´çš„æ¶æ„åˆ†æï¼ŒåŒ…æ‹¬ï¼š

        1. ç³»ç»Ÿæ¦‚è¿°ï¼š
           - æ ¸å¿ƒåŠŸèƒ½å’Œç›®æ ‡
           - å…³é”®éœ€æ±‚å’Œçº¦æŸ
           - æŠ€æœ¯é€‰å‹ç†ç”±

        2. æ¶æ„è®¾è®¡ï¼š
           - æ¶æ„æ¨¡å¼é€‰æ‹©
           - ç³»ç»Ÿåˆ†å±‚
           - æ¨¡å—åˆ’åˆ†
           - å…³é”®æ¥å£

        3. ä¾èµ–å…³ç³»ï¼š
           - æ¨¡å—é—´çš„ä¾èµ–
           - æ•°æ®æµå‘
           - äº¤äº’æ¨¡å¼

        4. æŠ€æœ¯å®ç°ï¼š
           - å…·ä½“æŠ€æœ¯æ ˆ
           - æ¡†æ¶é€‰æ‹©
           - éƒ¨ç½²æ–¹æ¡ˆ

        5. è´¨é‡å±æ€§ï¼š
           - æ€§èƒ½è€ƒè™‘
           - å®‰å…¨æªæ–½
           - å¯æ‰©å±•æ€§è®¾è®¡

        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
        {{
            "system_overview": {{
                "core_features": [],
                "key_requirements": [],
                "technical_choices": []
            }},
            "architecture_design": {{
                "patterns": [
                    {{
                        "name": "æ¨¡å¼åç§°",
                        "description": "æè¿°",
                        "layers": [
                            {{
                                "name": "å±‚çº§åç§°",
                                "responsibility": "èŒè´£",
                                "components": []
                            }}
                        ]
                    }}
                ],
                "key_interfaces": []
            }},
            "dependencies": {{
                "module_dependencies": [],
                "data_flows": [],
                "interaction_patterns": []
            }},
            "implementation": {{
                "tech_stack": [],
                "frameworks": [],
                "deployment": {{}}
            }},
            "quality_attributes": {{
                "performance": [],
                "security": [],
                "scalability": []
            }}
        }}
        """
        
        return await llm_call(prompt)
    
    async def extract_architecture_info(self, architecture_doc: str, llm_call) -> Dict:
        """ä»æŠ€æœ¯æ¶æ„æ–‡æ¡£ä¸­æå–æ¶æ„ä¿¡æ¯"""
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹æŠ€æœ¯æ¶æ„æ–‡æ¡£ï¼Œæå–å…³é”®çš„æ¶æ„ä¿¡æ¯ï¼š

        {architecture_doc}

        è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
        1. å·²å®šä¹‰çš„æ¶æ„æ¨¡å¼
        2. å„ä¸ªå±‚çº§çš„å®šä¹‰å’ŒèŒè´£
        3. æ¨¡å—é—´çš„ä¾èµ–å…³ç³»
        4. æŠ€æœ¯é€‰å‹å’Œçº¦æŸ
        5. å·²è¯†åˆ«çš„å…³é”®æ¨¡å—

        è¿”å›æ ¼å¼ä¸ºJSONï¼š
        {{
            "architecture_patterns": [
                {{
                    "name": "æ¨¡å¼åç§°",
                    "description": "æ¨¡å¼æè¿°",
                    "layers": [
                        {{
                            "name": "å±‚çº§åç§°",
                            "responsibility": "èŒè´£æè¿°",
                            "constraints": ["çº¦æŸ1", "çº¦æŸ2"]
                        }}
                    ]
                }}
            ],
            "dependencies": [
                {{
                    "from": "æºæ¨¡å—",
                    "to": "ç›®æ ‡æ¨¡å—",
                    "type": "ä¾èµ–ç±»å‹"
                }}
            ],
            "key_modules": [
                {{
                    "name": "æ¨¡å—åç§°",
                    "pattern": "æ‰€å±æ¨¡å¼",
                    "layer": "æ‰€å±å±‚çº§",
                    "description": "æè¿°"
                }}
            ],
            "technical_constraints": [
                {{
                    "category": "çº¦æŸç±»åˆ«",
                    "description": "å…·ä½“çº¦æŸ",
                    "rationale": "åŸå› "
                }}
            ]
        }}
        """
        
        return await llm_call(prompt)
    
    async def generate_mapping_doc(self, analysis: Dict, architecture_info: Dict, llm_call) -> str:
        """ç”Ÿæˆéœ€æ±‚åˆ°æ¶æ„çš„æ˜ å°„æ–‡æ¡£"""
        prompt = f"""
        åŸºäºä»¥ä¸‹åˆ†æç»“æœå’Œæ¶æ„ä¿¡æ¯ï¼Œç”Ÿæˆéœ€æ±‚åˆ°æ¶æ„çš„æ˜ å°„æ–‡æ¡£ï¼š

        éœ€æ±‚åˆ†æï¼š
        {json.dumps(analysis, ensure_ascii=False, indent=2)}

        æ¶æ„ä¿¡æ¯ï¼š
        {json.dumps(architecture_info, ensure_ascii=False, indent=2)}
        
        è¯·ç”Ÿæˆä¸€ä¸ªæ¸…æ™°çš„æ˜ å°„æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
        1. æ¯ä¸ªéœ€æ±‚å¦‚ä½•æ˜ å°„åˆ°å…·ä½“çš„æ¶æ„æ¨¡å¼å’Œå±‚çº§
        2. éœ€è¦åˆ›å»ºçš„å…·ä½“æ¨¡å—
        3. æ¨¡å—é—´çš„äº¤äº’æ–¹å¼
        4. æŠ€æœ¯å®ç°å»ºè®®

        è¿”å›Markdownæ ¼å¼çš„æ–‡æ¡£ã€‚
        """
        
        mapping_content = await llm_call(prompt)
        
        # ä¿å­˜æ˜ å°„æ–‡æ¡£
        mapping_file = self.input_path / "architecture_mapping.md"
        mapping_file.write_text(mapping_content)
        
        return mapping_content 